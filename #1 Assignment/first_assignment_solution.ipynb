{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Assignment #1: Pseudonymisation Techniques and Considerations\n",
    "- Dataset: Crossfit [Daset](https://data.world/bgadoci/crossfit-data) (In this assignment only the athletes file was used) \n",
    "- Credits: Dataset was put together by Sam Swift\n",
    "- ToDo: To run the jupyter notebook the requirements.txt need be installed (`pip install -r requirements.txt`)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd0b2ac563f828dd"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be93d85a454a3b2d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T14:36:58.370343Z",
     "start_time": "2024-02-21T14:36:58.308763Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   athlete_id           name               region          team  \\\n",
      "0      2554.0      Pj Ablang           South West   Double Edge   \n",
      "1      3517.0  Derek Abdella                  NaN           NaN   \n",
      "2      4691.0            NaN                  NaN           NaN   \n",
      "3      5164.0    Abo Brandon  Southern California  LAX CrossFit   \n",
      "\n",
      "              affiliate gender   age  height  weight   fran  ...  deadlift  \\\n",
      "0  Double Edge CrossFit   Male  24.0    70.0   166.0    NaN  ...     400.0   \n",
      "1                   NaN   Male  42.0    70.0   190.0    NaN  ...       NaN   \n",
      "2                   NaN    NaN   NaN     NaN     NaN    NaN  ...       NaN   \n",
      "3          LAX CrossFit   Male  40.0    67.0     NaN  211.0  ...     375.0   \n",
      "\n",
      "   backsq  pullups                                   eat  \\\n",
      "0   305.0      NaN                                   NaN   \n",
      "1     NaN      NaN                                   NaN   \n",
      "2     NaN      NaN                                   NaN   \n",
      "3   325.0     25.0  I eat 1-3 full cheat meals per week|   \n",
      "\n",
      "                                               train  \\\n",
      "0  I workout mostly at a CrossFit Affiliate|I hav...   \n",
      "1  I have a coach who determines my programming|I...   \n",
      "2                                                NaN   \n",
      "3  I workout mostly at a CrossFit Affiliate|I hav...   \n",
      "\n",
      "                                          background  \\\n",
      "0  I played youth or high school level sports|I r...   \n",
      "1        I played youth or high school level sports|   \n",
      "2                                                NaN   \n",
      "3        I played youth or high school level sports|   \n",
      "\n",
      "                                          experience  \\\n",
      "0  I began CrossFit with a coach (e.g. at an affi...   \n",
      "1  I began CrossFit with a coach (e.g. at an affi...   \n",
      "2                                                NaN   \n",
      "3  I began CrossFit by trying it alone (without a...   \n",
      "\n",
      "                                     schedule    howlong  retrieved_datetime  \n",
      "0  I do multiple workouts in a day 2x a week|  4+ years|                 NaN  \n",
      "1  I do multiple workouts in a day 2x a week|  4+ years|                 NaN  \n",
      "2                                         NaN        NaN                 NaN  \n",
      "3          I usually only do 1 workout a day|  4+ years|                 NaN  \n",
      "\n",
      "[4 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read csv as dataframe\n",
    "dataframe = pd.read_csv(\"reduced_athletes.csv\")\n",
    "\n",
    "#dataframe[\"test\"] = dataframe[\"height\"]\n",
    "#dataframe[\"height\"] = dataframe[\"weight\"]\n",
    "#dataframe[\"weight\"] = dataframe[\"test\"]\n",
    "\n",
    "#dataframe = dataframe.drop(columns=['test'])\n",
    "\n",
    "#dataframe.to_csv('athletes_new.csv', index=False)\n",
    "print(dataframe.iloc[:4])"
   ]
  },
  {
   "cell_type": "raw",
   "source": [
    "## 3.1 Pseudonymisation\n",
    "Goals:\n",
    "-  Determine which attributes qualify as explicit personally identifiable information (3.1.1)\n",
    "    - Why? \n",
    "    - What method was used to identify these? \n",
    "- Generate pseudonymous values for the identified attributes (3.1.2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b64615a1710ba2a"
  },
  {
   "cell_type": "markdown",
   "id": "a09a389f01e7c40",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.1.1 Identifying Attributes containing Personally Identifiable Information (PII)\n",
    "- In order to identify th attributes first a better understanding of the structure of the dataset needs to be obtained\n",
    "    - What columns does the dataset contain and in what format are the attribute values?\n",
    "        - Therefore, each column and the first value of each column (which is not empty or Null) is printed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: 'athlete_id', Example Data: 2554.0\n",
      "Column: 'name', Example Data: Pj Ablang\n",
      "Column: 'region', Example Data: South West\n",
      "Column: 'team', Example Data: Double Edge\n",
      "Column: 'affiliate', Example Data: Double Edge CrossFit\n",
      "Column: 'gender', Example Data: Male\n",
      "Column: 'age', Example Data: 24.0\n",
      "Column: 'height', Example Data: 70.0\n",
      "Column: 'weight', Example Data: 166.0\n",
      "Column: 'fran', Example Data: 211.0\n",
      "Column: 'helen', Example Data: 645.0\n",
      "Column: 'grace', Example Data: 300.0\n",
      "Column: 'filthy50', Example Data: 1053.0\n",
      "Column: 'fgonebad', Example Data: 0.0\n",
      "Column: 'run400', Example Data: 61.0\n",
      "Column: 'run5k', Example Data: 1081.0\n",
      "Column: 'candj', Example Data: 220.0\n",
      "Column: 'snatch', Example Data: 200.0\n",
      "Column: 'deadlift', Example Data: 400.0\n",
      "Column: 'backsq', Example Data: 305.0\n",
      "Column: 'pullups', Example Data: 25.0\n",
      "Column: 'eat', Example Data: I eat 1-3 full cheat meals per week|\n",
      "Column: 'train', Example Data: I workout mostly at a CrossFit Affiliate|I have a coach who determines my programming|I record my workouts|\n",
      "Column: 'background', Example Data: I played youth or high school level sports|I regularly play recreational sports|\n",
      "Column: 'experience', Example Data: I began CrossFit with a coach (e.g. at an affiliate)|I have attended one or more specialty courses|I have had a life changing experience due to CrossFit|\n",
      "Column: 'schedule', Example Data: I do multiple workouts in a day 2x a week|\n",
      "Column: 'howlong', Example Data: 4+ years|\n",
      "Column: 'retrieved_datetime', Example Data: None\n"
     ]
    }
   ],
   "source": [
    "def get_first_not_not_empty_value(df_column):\n",
    "    return df_column.dropna().iloc[0] if not df_column.dropna().empty else None\n",
    "\n",
    "# Iterate each column \n",
    "for column in dataframe.columns:\n",
    "    first_value = get_first_not_not_empty_value(dataframe[column])\n",
    "    print(f\"Column: '{column}', Example Data: {first_value}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T14:36:58.402553Z",
     "start_time": "2024-02-21T14:36:58.369510Z"
    }
   },
   "id": "3669191d576f3aae"
  },
  {
   "cell_type": "markdown",
   "id": "6ed2670d051f539a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "- By inspecting the different columns and the data format, several attributes which have the potential to contain explicit personally identifiable information can be identified\n",
    "    - `athelete_id`\n",
    "        -  This really depends on the usage of this id! Considerations to take into account are: \n",
    "            - Is the `athlete_id` only used as an internal id of this dataset or does it maybe even refer to an official id?\n",
    "            - Are there other datasets available which may have a similar source to this dataset? Thus, these other datasets may use the same `athlete_id`\n",
    "    - `name`\n",
    "        - The name allows to identify an individual\n",
    "    - `team`\n",
    "        - Depending on the size of the team, this could allow to identify a specific athlete\n",
    "    - `affiliate` \n",
    "        - Depending on the affiliate and the amount of contracted athletes, this could allow to identify an individual\n",
    "    - All stats of the athletes\n",
    "        - If an athlete has really remarkable stats (maybe even a world record in a category), this could allow to identify the individual\n",
    "    - `train` \n",
    "        - If an athlete has a special and famous training routine, this could allow to identify him\n",
    "    - `background`\n",
    "        - If an athlete has a famous background or mentions names, this could allow to identify him\n",
    "    - `experience`\n",
    "        - If an athlete mentions concrete information about his experience (e.g. name of current coach), this could allow to identify him\n",
    "\n",
    "-> As can be seen, all columns could potentially contain outliers which could be then used to identify an individual. As agreed on, for each of the columns (only those holding numbers or names) potentially leaking PII one anonymization technique was chosen which keeps the data loss as minimal as possible without leaking obvious PII. It is important to note, that there could still be columns containing PII. However, this chance for outliers was accepted in this assignment. Columns containing descriptions (e.g. train, background and experience) where to anonymized and thus the chance for outliers accepted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2e7f8a58b909df",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.1.2 Pseudonymizing\n",
    "- For pseudonymisation especially the name is suitable, because it can be easily replaced with a fake name, without being as obvious or destroying the purpose of the dataset\n",
    "- With the help of the `anonymizedf` library new fake names can be created for the `name` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e1f75b29dbfdecd",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T14:36:58.787764Z",
     "start_time": "2024-02-21T14:36:58.469116Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   athlete_id               region          team             affiliate gender  \\\n",
      "0      2554.0           South West   Double Edge  Double Edge CrossFit   Male   \n",
      "1      3517.0                  NaN           NaN                   NaN   Male   \n",
      "2      4691.0                  NaN           NaN                   NaN    NaN   \n",
      "3      5164.0  Southern California  LAX CrossFit          LAX CrossFit   Male   \n",
      "\n",
      "    age  height  weight   fran  helen  ...  backsq  pullups  \\\n",
      "0  24.0    70.0   166.0    NaN    NaN  ...   305.0      NaN   \n",
      "1  42.0    70.0   190.0    NaN    NaN  ...     NaN      NaN   \n",
      "2   NaN     NaN     NaN    NaN    NaN  ...     NaN      NaN   \n",
      "3  40.0    67.0     NaN  211.0  645.0  ...   325.0     25.0   \n",
      "\n",
      "                                    eat  \\\n",
      "0                                   NaN   \n",
      "1                                   NaN   \n",
      "2                                   NaN   \n",
      "3  I eat 1-3 full cheat meals per week|   \n",
      "\n",
      "                                               train  \\\n",
      "0  I workout mostly at a CrossFit Affiliate|I hav...   \n",
      "1  I have a coach who determines my programming|I...   \n",
      "2                                                NaN   \n",
      "3  I workout mostly at a CrossFit Affiliate|I hav...   \n",
      "\n",
      "                                          background  \\\n",
      "0  I played youth or high school level sports|I r...   \n",
      "1        I played youth or high school level sports|   \n",
      "2                                                NaN   \n",
      "3        I played youth or high school level sports|   \n",
      "\n",
      "                                          experience  \\\n",
      "0  I began CrossFit with a coach (e.g. at an affi...   \n",
      "1  I began CrossFit with a coach (e.g. at an affi...   \n",
      "2                                                NaN   \n",
      "3  I began CrossFit by trying it alone (without a...   \n",
      "\n",
      "                                     schedule    howlong  retrieved_datetime  \\\n",
      "0  I do multiple workouts in a day 2x a week|  4+ years|                 NaN   \n",
      "1  I do multiple workouts in a day 2x a week|  4+ years|                 NaN   \n",
      "2                                         NaN        NaN                 NaN   \n",
      "3          I usually only do 1 workout a day|  4+ years|                 NaN   \n",
      "\n",
      "            name  \n",
      "0   Fiona Barnes  \n",
      "1      Lucy Dyer  \n",
      "2   Kirsty Patel  \n",
      "3  Justin Harris  \n",
      "\n",
      "[4 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "from anonymizedf import anonymizedf\n",
    "\n",
    "# Prepare the data to be anonymized\n",
    "an = anonymizedf.anonymize(dataframe)\n",
    "\n",
    "# Add new column with fake name\n",
    "an.fake_names(\"name\")\n",
    "\n",
    "# Drop old original name column\n",
    "dataframe = dataframe.drop(columns=['name'])\n",
    "\n",
    "# Rename Fake_name column in name\n",
    "dataframe = dataframe.rename(columns={'Fake_name': 'name'})\n",
    "\n",
    "print(dataframe.iloc[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d638b8091b0fee",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3.2 Randomisation\n",
    "Goal:\n",
    "- Use randomisation technique to generate random strings (no meaning) (3.2.1)\n",
    "- Use randomisation technique to generate random but meaningful replacements and create lookup table (3.2.2)\n",
    "\n",
    "### 3.2.1 Random Strings\n",
    "1. Identify columns to replace with random strings\n",
    "    - Here columns containing words can be used \n",
    "        - `name`\n",
    "        - `region`\n",
    "        - `team`\n",
    "        - `affiliate` \n",
    "2. Generate a function which is responsible for generating random values for replacement\n",
    "3. Overwrite each value in respective attributes by using the generated value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aea49738582c6a6e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T14:36:59.278011Z",
     "start_time": "2024-02-21T14:36:58.843093Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   athlete_id           region                  team  \\\n",
      "0      2554.0  XjnrEzWxUXjJaqN  FnDcmeUydPRQFApSrhzS   \n",
      "1      3517.0  RtZhjtLjtRJkvmx  iNyOnYFOcqdmNhNySMby   \n",
      "2      4691.0  BwBtpdcxXSihCvD  XvecgkZlSOdEuOInQZRU   \n",
      "3      5164.0  cgTjOZeUXKRAAQT  YMcovfvIDkBmfhNMjpMY   \n",
      "\n",
      "                   affiliate gender   age  height  weight   fran  helen  ...  \\\n",
      "0  zidQDLmYQxyMvTvFsGwPiUSxP   Male  24.0    70.0   166.0    NaN    NaN  ...   \n",
      "1  SHGOqIBkETiYwZXyHPVRCkWNn   Male  42.0    70.0   190.0    NaN    NaN  ...   \n",
      "2  pcjjixiKrLKOYlcQxeqBGdPsU    NaN   NaN     NaN     NaN    NaN    NaN  ...   \n",
      "3  fabbAyeFDVVrMEncwFERCgekx   Male  40.0    67.0     NaN  211.0  645.0  ...   \n",
      "\n",
      "   backsq  pullups                                   eat  \\\n",
      "0   305.0      NaN                                   NaN   \n",
      "1     NaN      NaN                                   NaN   \n",
      "2     NaN      NaN                                   NaN   \n",
      "3   325.0     25.0  I eat 1-3 full cheat meals per week|   \n",
      "\n",
      "                                               train  \\\n",
      "0  I workout mostly at a CrossFit Affiliate|I hav...   \n",
      "1  I have a coach who determines my programming|I...   \n",
      "2                                                NaN   \n",
      "3  I workout mostly at a CrossFit Affiliate|I hav...   \n",
      "\n",
      "                                          background  \\\n",
      "0  I played youth or high school level sports|I r...   \n",
      "1        I played youth or high school level sports|   \n",
      "2                                                NaN   \n",
      "3        I played youth or high school level sports|   \n",
      "\n",
      "                                          experience  \\\n",
      "0  I began CrossFit with a coach (e.g. at an affi...   \n",
      "1  I began CrossFit with a coach (e.g. at an affi...   \n",
      "2                                                NaN   \n",
      "3  I began CrossFit by trying it alone (without a...   \n",
      "\n",
      "                                     schedule    howlong  retrieved_datetime  \\\n",
      "0  I do multiple workouts in a day 2x a week|  4+ years|                 NaN   \n",
      "1  I do multiple workouts in a day 2x a week|  4+ years|                 NaN   \n",
      "2                                         NaN        NaN                 NaN   \n",
      "3          I usually only do 1 workout a day|  4+ years|                 NaN   \n",
      "\n",
      "         name  \n",
      "0  sCwBLsgCfr  \n",
      "1  QOpPopqpNV  \n",
      "2  HdxywQADDT  \n",
      "3  KLAfQVfDev  \n",
      "\n",
      "[4 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "# Define function to create random string\n",
    "def generate_random_string(length):\n",
    "    letters = string.ascii_letters\n",
    "    return ''.join(random.choice(letters) for _ in range(length))\n",
    "\n",
    "# Apply randomization on specified columns\n",
    "dataframe['name'] = dataframe['name'].apply(lambda x: generate_random_string(10))\n",
    "dataframe['region'] = dataframe['region'].apply(lambda x: generate_random_string(15))\n",
    "dataframe['team'] = dataframe['team'].apply(lambda x: generate_random_string(20))\n",
    "dataframe['affiliate'] = dataframe['affiliate'].apply(lambda x: generate_random_string(25))\n",
    "\n",
    "print(dataframe.iloc[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72fe81893e96ef",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.2.2 Randomization with meaningful strings\n",
    "1. Identify columns suitable\n",
    "    - name, region, team, affiliate\n",
    "        -  For randomizing the name, the first letter will be kept equal to the original in order to keep similarities\n",
    "2. Write functionality to randomize the values\n",
    "- Interchange Values in Columns Name, Region, Team, Affiliate with meaningful strings to randomize and print out the lookuptable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   athlete_id             name      region             team  \\\n",
      "0      2554.0      Will Howard         NaN              NaN   \n",
      "1      3517.0  Brian Honeycutt         NaN  CrossFit Merced   \n",
      "2      4691.0   Carlos Andrade  North East              NaN   \n",
      "3      5164.0   dano bodsworth         NaN              NaN   \n",
      "\n",
      "             affiliate gender   age  height  weight   fran  ...  deadlift  \\\n",
      "0                  NaN   Male  24.0    70.0   166.0    NaN  ...     400.0   \n",
      "1      CrossFit Draper   Male  42.0    70.0   190.0    NaN  ...       NaN   \n",
      "2                  NaN    NaN   NaN     NaN     NaN    NaN  ...       NaN   \n",
      "3  CrossFit Gothenburg   Male  40.0    67.0     NaN  211.0  ...     375.0   \n",
      "\n",
      "   backsq  pullups                                   eat  \\\n",
      "0   305.0      NaN                                   NaN   \n",
      "1     NaN      NaN                                   NaN   \n",
      "2     NaN      NaN                                   NaN   \n",
      "3   325.0     25.0  I eat 1-3 full cheat meals per week|   \n",
      "\n",
      "                                               train  \\\n",
      "0  I workout mostly at a CrossFit Affiliate|I hav...   \n",
      "1  I have a coach who determines my programming|I...   \n",
      "2                                                NaN   \n",
      "3  I workout mostly at a CrossFit Affiliate|I hav...   \n",
      "\n",
      "                                          background  \\\n",
      "0  I played youth or high school level sports|I r...   \n",
      "1        I played youth or high school level sports|   \n",
      "2                                                NaN   \n",
      "3        I played youth or high school level sports|   \n",
      "\n",
      "                                          experience  \\\n",
      "0  I began CrossFit with a coach (e.g. at an affi...   \n",
      "1  I began CrossFit with a coach (e.g. at an affi...   \n",
      "2                                                NaN   \n",
      "3  I began CrossFit by trying it alone (without a...   \n",
      "\n",
      "                                     schedule    howlong  retrieved_datetime  \n",
      "0  I do multiple workouts in a day 2x a week|  4+ years|                 NaN  \n",
      "1  I do multiple workouts in a day 2x a week|  4+ years|                 NaN  \n",
      "2                                         NaN        NaN                 NaN  \n",
      "3          I usually only do 1 workout a day|  4+ years|                 NaN  \n",
      "\n",
      "[4 rows x 28 columns]\n",
      "            name               region          team             affiliate  \\\n",
      "0      Pj Ablang           South West   Double Edge  Double Edge CrossFit   \n",
      "1  Derek Abdella                  NaN           NaN                   NaN   \n",
      "2            NaN                  NaN           NaN                   NaN   \n",
      "3    Abo Brandon  Southern California  LAX CrossFit          LAX CrossFit   \n",
      "\n",
      "   randomized_name randomized_region  randomized_team randomized_affiliate  \n",
      "0      Will Howard               NaN              NaN                  NaN  \n",
      "1  Brian Honeycutt               NaN  CrossFit Merced      CrossFit Draper  \n",
      "2   Carlos Andrade        North East              NaN                  NaN  \n",
      "3   dano bodsworth               NaN              NaN  CrossFit Gothenburg  \n"
     ]
    }
   ],
   "source": [
    "# To see the changes properly we have to reload the initial data\n",
    "dataframe = pd.read_csv(\"reduced_athletes.csv\")\n",
    "\n",
    "# Copy the original values in mapping dataframe\n",
    "dataframe_mapping = dataframe[['name', 'region', 'team', 'affiliate']].copy()\n",
    "\n",
    "# Interchange values for region, team and affiliate\n",
    "def interchange_values(column_name):\n",
    "    dataframe[column_name] = dataframe[column_name].sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Randomize name, region, team and affiliate\n",
    "interchange_values('name')\n",
    "interchange_values('region')\n",
    "interchange_values('team')\n",
    "interchange_values('affiliate')\n",
    "\n",
    "# Copy the modified values in mapping dataframe\n",
    "dataframe_mapping[['randomized_name', 'randomized_region', 'randomized_team', 'randomized_affiliate']] = dataframe[['name', 'region', 'team', 'affiliate']].copy()\n",
    "\n",
    "# Save mapping to csv\n",
    "dataframe_mapping.to_csv('athletes_mapping.csv', index=False)\n",
    "\n",
    "print(dataframe.iloc[:4])\n",
    "print(dataframe_mapping.iloc[:4])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T14:36:59.368315Z",
     "start_time": "2024-02-21T14:36:59.279845Z"
    }
   },
   "id": "fe9526ff779442bc"
  },
  {
   "cell_type": "markdown",
   "id": "c59dc5a07acdb83d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3.3 Aggregation\n",
    "Goal:\n",
    "- Determine attributes which qualify for aggregation (3.3.1)\n",
    "- Write a function to perform that aggregation process (3.3.2)\n",
    "\n",
    "### 3.3.1 Determine Attributes for Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The script iterates through each column in the DataFrame and prints the column name along with the first non-empty value in that column:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "42c548ad3a5e556c"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdfc0b43c8b43a28",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T14:36:59.396753Z",
     "start_time": "2024-02-21T14:36:59.367516Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: 'athlete_id', Example Data: 2554.0\n",
      "Column: 'name', Example Data: Will Howard\n",
      "Column: 'region', Example Data: North East\n",
      "Column: 'team', Example Data: CrossFit Merced\n",
      "Column: 'affiliate', Example Data: CrossFit Draper\n",
      "Column: 'gender', Example Data: Male\n",
      "Column: 'age', Example Data: 24.0\n",
      "Column: 'height', Example Data: 70.0\n",
      "Column: 'weight', Example Data: 166.0\n",
      "Column: 'fran', Example Data: 211.0\n",
      "Column: 'helen', Example Data: 645.0\n",
      "Column: 'grace', Example Data: 300.0\n",
      "Column: 'filthy50', Example Data: 1053.0\n",
      "Column: 'fgonebad', Example Data: 0.0\n",
      "Column: 'run400', Example Data: 61.0\n",
      "Column: 'run5k', Example Data: 1081.0\n",
      "Column: 'candj', Example Data: 220.0\n",
      "Column: 'snatch', Example Data: 200.0\n",
      "Column: 'deadlift', Example Data: 400.0\n",
      "Column: 'backsq', Example Data: 305.0\n",
      "Column: 'pullups', Example Data: 25.0\n",
      "Column: 'eat', Example Data: I eat 1-3 full cheat meals per week|\n",
      "Column: 'train', Example Data: I workout mostly at a CrossFit Affiliate|I have a coach who determines my programming|I record my workouts|\n",
      "Column: 'background', Example Data: I played youth or high school level sports|I regularly play recreational sports|\n",
      "Column: 'experience', Example Data: I began CrossFit with a coach (e.g. at an affiliate)|I have attended one or more specialty courses|I have had a life changing experience due to CrossFit|\n",
      "Column: 'schedule', Example Data: I do multiple workouts in a day 2x a week|\n",
      "Column: 'howlong', Example Data: 4+ years|\n",
      "Column: 'retrieved_datetime', Example Data: None\n"
     ]
    }
   ],
   "source": [
    "def get_first_not_not_empty_value(df_column):\n",
    "    return df_column.dropna().iloc[0] if not df_column.dropna().empty else None\n",
    "\n",
    "# Print each column with its first not empty value\n",
    "for column in dataframe.columns:\n",
    "    first_value = get_first_not_not_empty_value(dataframe[column])\n",
    "    print(f\"Column: '{column}', Example Data: {first_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32c31ee64889069",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "- Numerical attributes can be easily aggregated\n",
    "- Especially those related to information about the individual are suitable for aggregation\n",
    "    - `age`\n",
    "    - `height` \n",
    "    - `weight`\n",
    "- To be able to identify different levels of values, the extremes have to be identified "
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The script prints the minimum and maximum values for 'age,' 'height,' and 'weight' columns:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5826be06ba973a42"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dabc635f8ab91128",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T14:36:59.397384Z",
     "start_time": "2024-02-21T14:36:59.387682Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum age': 7257     13.0\n",
      "11381    15.0\n",
      "10631    16.0\n",
      "2397     17.0\n",
      "4295     17.0\n",
      "Name: age, dtype: float64, Maximum age: 4446     115.0\n",
      "11766     53.0\n",
      "5180      48.0\n",
      "13161     48.0\n",
      "17790     48.0\n",
      "Name: age, dtype: float64\n",
      "Minimum height': 6157     0.0\n",
      "7384     0.0\n",
      "10847    0.0\n",
      "17122    0.0\n",
      "19320    0.0\n",
      "19665    0.0\n",
      "10409    1.0\n",
      "13883    1.0\n",
      "14223    1.0\n",
      "18836    1.0\n",
      "Name: height, dtype: float64, Maximum height: 10820    314.0\n",
      "18443    283.0\n",
      "13920    157.0\n",
      "5014     100.0\n",
      "9221      84.0\n",
      "19085     84.0\n",
      "2146      81.0\n",
      "9743      81.0\n",
      "9922      81.0\n",
      "6852      80.0\n",
      "Name: height, dtype: float64\n",
      "Minimum weight': 19320     2.0\n",
      "14344     5.0\n",
      "17344     7.0\n",
      "12453    10.0\n",
      "12427    13.0\n",
      "16843    41.0\n",
      "829      67.0\n",
      "1308     67.0\n",
      "960      70.0\n",
      "3211     70.0\n",
      "Name: weight, dtype: float64, Maximum weight: 6157     2205.0\n",
      "19939    1783.0\n",
      "10820     708.0\n",
      "3323      485.0\n",
      "5014      400.0\n",
      "13920     397.0\n",
      "14087     395.0\n",
      "6785      380.0\n",
      "12509     325.0\n",
      "3732      320.0\n",
      "Name: weight, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Minimum age': {dataframe['age'].nsmallest(5)}, Maximum age: {dataframe['age'].nlargest(5)}\")\n",
    "print(f\"Minimum height': {dataframe['height'].nsmallest(10)}, Maximum height: {dataframe['height'].nlargest(10)}\")\n",
    "print(f\"Minimum weight': {dataframe['weight'].nsmallest(10)}, Maximum weight: {dataframe['weight'].nlargest(10)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c523edd6a9c147",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "- Because even by observing ten extremes for the height and weight the values didn't make sense, in the following average values for the entire population were taken"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.3.1 Perform Aggregation\n",
    "\n",
    "The script defines bins and labels for 'age,' 'height,' and 'weight' columns, categorizing the numerical values into bins. This provides a more concise representation of the data distribution:\n",
    "Finally, the modified DataFrame, incorporating binning for 'age,' 'height,' and 'weight,' is printed:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "59467bf84ccd64eb"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a37f1ccdf7063b7",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T14:36:59.419648Z",
     "start_time": "2024-02-21T14:36:59.400112Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   athlete_id             name      region             team  \\\n",
      "0      2554.0      Will Howard         NaN              NaN   \n",
      "1      3517.0  Brian Honeycutt         NaN  CrossFit Merced   \n",
      "2      4691.0   Carlos Andrade  North East              NaN   \n",
      "3      5164.0   dano bodsworth         NaN              NaN   \n",
      "\n",
      "             affiliate gender    age height weight   fran  ...  deadlift  \\\n",
      "0                  NaN   Male  19-30  0-159    NaN    NaN  ...     400.0   \n",
      "1      CrossFit Draper   Male  31-45  0-159    NaN    NaN  ...       NaN   \n",
      "2                  NaN    NaN    NaN    NaN    NaN    NaN  ...       NaN   \n",
      "3  CrossFit Gothenburg   Male  31-45  0-159    NaN  211.0  ...     375.0   \n",
      "\n",
      "   backsq  pullups                                   eat  \\\n",
      "0   305.0      NaN                                   NaN   \n",
      "1     NaN      NaN                                   NaN   \n",
      "2     NaN      NaN                                   NaN   \n",
      "3   325.0     25.0  I eat 1-3 full cheat meals per week|   \n",
      "\n",
      "                                               train  \\\n",
      "0  I workout mostly at a CrossFit Affiliate|I hav...   \n",
      "1  I have a coach who determines my programming|I...   \n",
      "2                                                NaN   \n",
      "3  I workout mostly at a CrossFit Affiliate|I hav...   \n",
      "\n",
      "                                          background  \\\n",
      "0  I played youth or high school level sports|I r...   \n",
      "1        I played youth or high school level sports|   \n",
      "2                                                NaN   \n",
      "3        I played youth or high school level sports|   \n",
      "\n",
      "                                          experience  \\\n",
      "0  I began CrossFit with a coach (e.g. at an affi...   \n",
      "1  I began CrossFit with a coach (e.g. at an affi...   \n",
      "2                                                NaN   \n",
      "3  I began CrossFit by trying it alone (without a...   \n",
      "\n",
      "                                     schedule    howlong  retrieved_datetime  \n",
      "0  I do multiple workouts in a day 2x a week|  4+ years|                 NaN  \n",
      "1  I do multiple workouts in a day 2x a week|  4+ years|                 NaN  \n",
      "2                                         NaN        NaN                 NaN  \n",
      "3          I usually only do 1 workout a day|  4+ years|                 NaN  \n",
      "\n",
      "[4 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "bins_age = [0, 18, 30, 45, 60, 100]\n",
    "labels_age = ['0-18', '19-30', '31-45', '46-60', '60+']\n",
    "\n",
    "bins_height = [0, 159, 169, 179, 189, 199, 220]\n",
    "labels_height = ['0-159', '160-169', '170-179', '180-189', '190-199', '200+']\n",
    "\n",
    "bins_weight = [0, 49, 59, 69, 79, 89, 99, 130]\n",
    "labels_weight = ['0-49', '50-59', '60-69', '70-79', '80-89', '90-99', '100+']\n",
    "\n",
    "dataframe['age'] = pd.cut(dataframe['age'], bins=bins_age, labels=labels_age)\n",
    "dataframe['height'] = pd.cut(dataframe['height'], bins=bins_height, labels=labels_height)\n",
    "dataframe['weight'] = pd.cut(dataframe['weight'], bins=bins_weight, labels=labels_weight)\n",
    "\n",
    "print(dataframe.iloc[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff1f6ae44fdd428",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3.4 Perturbation\n",
    "Goal:\n",
    "- Select attributes to add noise to (3.4.1)\n",
    "- Implement the functionality to add the noise (3.4.2)\n",
    "    - The original distribution of values should be preserved \n",
    "- Analyse distribution of original data and then with noise added (3.4.3)\n",
    "\n",
    "### 3.4.1 Select attributes\n",
    "- Similar to the aggregation, perturbation as well fits best for numbers as attribute values \n",
    "- Because the stats of the athletes are the main subject of the dataset they should normally be no noise added to them\n",
    "    - Even more, the correctness of the value really matters in order to be able to compare different athletes. Here already a small noise is not good\n",
    "- However, as already mentioned in 3.1 this kind of information loss is accepted in this assignment\n",
    "- Therefore, the stats will be pertubated \n",
    "\n",
    "### 3.4.2 Pertubate Values\n",
    "- Standard deviation was used to determine noise\n",
    "\n",
    "The initial step involves loading the athlete dataset ('athletes.csv') using the pandas library:\n",
    "Continuous variables to be perturbed are explicitly specified:\n",
    "Statistical properties (mean and standard deviation) of non-missing numeric values in the selected columns are analyzed before perturbation:\n",
    "Non-missing numeric values in each specified column are perturbed by adding random noise, determined by a noise factor (in this case, 40). The perturbed data is then rounded and updated in the DataFrame:\n",
    "Statistical properties of non-missing numeric values are re-analyzed after perturbation:\n",
    "The final step involves saving the perturbed data back to the original CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f258df58c6fdb35f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T14:36:59.741598Z",
     "start_time": "2024-02-21T14:36:59.461614Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Perturbation:\n",
      "Mean pullups (Before): 54.33285224607613\n",
      "Std Dev pullups (Before): 1343.1702701767042\n",
      "Mean helen (Before): 572.4723604925334\n",
      "Std Dev helen (Before): 273.76002359692393\n",
      "Mean grace (Before): 200.4279379157428\n",
      "Std Dev grace (Before): 261.67976488928326\n",
      "Mean filthy50 (Before): 1484.3365656565657\n",
      "Std Dev filthy50 (Before): 751.784698558161\n",
      "Mean fgonebad (Before): 2662.8715549936787\n",
      "Std Dev fgonebad (Before): 134306.36962780636\n",
      "Mean run400 (Before): 125.09800490024502\n",
      "Std Dev run400 (Before): 458.29793174880473\n",
      "Mean run5k (Before): 1441.795461243737\n",
      "Std Dev run5k (Before): 4477.4137456466215\n",
      "Mean candj (Before): 228.72283755274262\n",
      "Std Dev candj (Before): 104.2163578131099\n",
      "Mean snatch (Before): 177.13939067133998\n",
      "Std Dev snatch (Before): 86.75952319600974\n",
      "Mean deadlift (Before): 395.47260612043436\n",
      "Std Dev deadlift (Before): 176.72956272616608\n",
      "Mean backsq (Before): 322.54908763813927\n",
      "Std Dev backsq (Before): 142.86413918578222\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data from the CSV file\n",
    "#dataframe = pd.read_csv('athletes.csv')\n",
    "\n",
    "columns_to_perturb = ['pullups', 'helen', 'grace', 'filthy50', 'fgonebad', 'run400', 'run5k', 'candj', 'snatch', 'deadlift', 'backsq']\n",
    "\n",
    "# Analyze the non-missing numeric values before perturbation\n",
    "stats_before_perturbation = {}\n",
    "for column in columns_to_perturb:\n",
    "    data = dataframe[column].values\n",
    "    non_missing_values = [value for value in data if not pd.isna(value)]\n",
    "    mean_before = np.mean(non_missing_values)\n",
    "    std_dev_before = np.std(non_missing_values)\n",
    "    stats_before_perturbation[column] = {'mean_before': mean_before, 'std_dev_before': std_dev_before}\n",
    "\n",
    "print(\"Before Perturbation:\")\n",
    "for column, stats in stats_before_perturbation.items():\n",
    "    print(f\"Mean {column} (Before): {stats['mean_before']}\")\n",
    "    print(f\"Std Dev {column} (Before): {stats['std_dev_before']}\")\n",
    "\n",
    "# Choose a noise factor\n",
    "noise_factor = 40  # Adjust this based on your privacy requirements\n",
    "\n",
    "# Perturb the non-missing numeric values for each specified column\n",
    "for column in columns_to_perturb:\n",
    "    perturbed_data = []\n",
    "    for value in dataframe[column]:\n",
    "        if not pd.isna(value):\n",
    "            perturbed_value = value + np.random.normal(0, noise_factor)\n",
    "            perturbed_value = int(abs(round(perturbed_value)))\n",
    "            perturbed_data.append(perturbed_value)\n",
    "        else:\n",
    "            perturbed_data.append(np.nan)\n",
    "    dataframe[column] = perturbed_data  # Update the column in the DataFrame with perturbed data\n",
    "\n",
    "\n",
    "# Save the perturbed data back to a CSV file without scientific notation\n",
    "dataframe.to_csv('athletes_anonyzmized.csv', index=False, float_format='%.0f')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.4.3 Analyze after Pertubation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9608137f7b0e90b4"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After Perturbation:\n",
      "Mean pullups (After): 64.53653256359372\n",
      "Std Dev pullups (After): 1343.9850628793006\n",
      "Mean helen (After): 572.432800628766\n",
      "Std Dev helen (After): 276.74878636662504\n",
      "Mean grace (After): 200.2911308203991\n",
      "Std Dev grace (After): 264.24847573446766\n",
      "Mean filthy50 (After): 1484.7951515151515\n",
      "Std Dev filthy50 (After): 753.3893401390002\n",
      "Mean fgonebad (After): 2668.3597977243994\n",
      "Std Dev fgonebad (After): 134305.43518167015\n",
      "Mean run400 (After): 125.60868043402171\n",
      "Std Dev run400 (After): 459.6962269887684\n",
      "Mean run5k (After): 1443.3330386089008\n",
      "Std Dev run5k (After): 4477.281381059619\n",
      "Mean candj (After): 231.42536919831224\n",
      "Std Dev candj (After): 107.3964419746243\n",
      "Mean snatch (After): 178.96899433809654\n",
      "Std Dev snatch (After): 92.30652955698116\n",
      "Mean deadlift (After): 398.74531095755185\n",
      "Std Dev deadlift (After): 175.7533152701738\n",
      "Mean backsq (After): 324.2044461578001\n",
      "Std Dev backsq (After): 144.08270354051146\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'athletes.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 20\u001B[0m\n\u001B[1;32m     14\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mStd Dev \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcolumn\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m (After): \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstats[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstd_dev_after\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     17\u001B[0m fig, (ax1,ax2) \u001B[38;5;241m=\u001B[39m plt\u001B[38;5;241m.\u001B[39msubplots(nrows\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, ncols\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m, sharey\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m20\u001B[39m,\u001B[38;5;241m10\u001B[39m))\n\u001B[1;32m     18\u001B[0m ax1\u001B[38;5;241m.\u001B[39mhist(\n\u001B[1;32m     19\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhelen\u001B[39m\u001B[38;5;124m'\u001B[39m, \n\u001B[0;32m---> 20\u001B[0m     data\u001B[38;5;241m=\u001B[39m\u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mathletes.csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m,\n\u001B[1;32m     21\u001B[0m     bins \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marange(start\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m, stop\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2_000\u001B[39m, step\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m200\u001B[39m),\n\u001B[1;32m     22\u001B[0m )\n\u001B[1;32m     23\u001B[0m ax1\u001B[38;5;241m.\u001B[39mtitle\u001B[38;5;241m.\u001B[39mset_text(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mOriginal Distribution\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     24\u001B[0m ax2\u001B[38;5;241m.\u001B[39mhist(\n\u001B[1;32m     25\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhelen\u001B[39m\u001B[38;5;124m'\u001B[39m, \n\u001B[1;32m     26\u001B[0m     data\u001B[38;5;241m=\u001B[39mdataframe, \n\u001B[1;32m     27\u001B[0m     bins \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marange(start\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m, stop\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2_000\u001B[39m, step\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m200\u001B[39m),\n\u001B[1;32m     28\u001B[0m )\n",
      "File \u001B[0;32m~/PycharmProjects/PPOD/.venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:948\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[1;32m    935\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m    936\u001B[0m     dialect,\n\u001B[1;32m    937\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    944\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[1;32m    945\u001B[0m )\n\u001B[1;32m    946\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m--> 948\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/PPOD/.venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:611\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    608\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[1;32m    610\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[0;32m--> 611\u001B[0m parser \u001B[38;5;241m=\u001B[39m \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    613\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[1;32m    614\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[0;32m~/PycharmProjects/PPOD/.venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1448\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m   1445\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m   1447\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1448\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/PPOD/.venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1705\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[0;34m(self, f, engine)\u001B[0m\n\u001B[1;32m   1703\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[1;32m   1704\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 1705\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1706\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1707\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1708\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1709\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1710\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1711\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1712\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1713\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1714\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1715\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1716\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[0;32m~/PycharmProjects/PPOD/.venv/lib/python3.9/site-packages/pandas/io/common.py:863\u001B[0m, in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    858\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m    859\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[1;32m    860\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[1;32m    861\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[1;32m    862\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[0;32m--> 863\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    864\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    865\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    866\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    867\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    868\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    869\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    870\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    871\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[1;32m    872\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'athletes.csv'"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 2000x1000 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Analyze the non-missing numeric values after perturbation\n",
    "stats_after_perturbation = {}\n",
    "for column in columns_to_perturb:\n",
    "    non_missing_values_after = [value for value in dataframe[column] if not pd.isna(value)]\n",
    "    mean_after = np.mean(non_missing_values_after)\n",
    "    std_dev_after = np.std(non_missing_values_after)\n",
    "    stats_after_perturbation[column] = {'mean_after': mean_after, 'std_dev_after': std_dev_after}\n",
    "\n",
    "print(\"\\nAfter Perturbation:\")\n",
    "for column, stats in stats_after_perturbation.items():\n",
    "    print(f\"Mean {column} (After): {stats['mean_after']}\")\n",
    "    print(f\"Std Dev {column} (After): {stats['std_dev_after']}\")\n",
    "    \n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(nrows=1, ncols=2, sharey=True, figsize=(20,10))\n",
    "ax1.hist(\n",
    "    'helen', \n",
    "    data=pd.read_csv('athletes.csv'),\n",
    "    bins = np.arange(start=100, stop=2_000, step=200),\n",
    ")\n",
    "ax1.title.set_text('Original Distribution')\n",
    "ax2.hist(\n",
    "    'helen', \n",
    "    data=dataframe, \n",
    "    bins = np.arange(start=100, stop=2_000, step=200),\n",
    ")\n",
    "ax2.title.set_text('Distribution with noise added')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T14:37:00.437943Z",
     "start_time": "2024-02-21T14:36:59.745859Z"
    }
   },
   "id": "d8f6b2643b725d7e"
  },
  {
   "cell_type": "markdown",
   "id": "e3084722e47e63b6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3.5 Data Analysis\n",
    "Goal:\n",
    "- Determine data loss using function (3.5.1)\n",
    "- Discuss pros and cons (3.5.2)\n",
    "- attributes included in the information loss function: ['pullups', 'helen', 'grace', 'filthy50', 'fgonebad', 'run400', 'run5k', 'candj', 'snatch', 'deadlift', 'backsq'] \n",
    "- maybe aggregated values: age, height, weight, but they are not continious variables, so they wont be respected in the following informatiin loss function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The initial step involves reading two CSV files, 'athletes.csv' and 'athletes_og.csv', using the pandas library, in which the athletes_og.csv is the original file and the athletes.csv is the file containing the perturbed continuous values.\n",
    "Aggregated, randomized and pseudonimized are not continuous and are therefore not considered in the Data Analysis.\n",
    "The Continuous variables to be analysed are explicitly specified.\n",
    "A function named 'calculate_information_loss' is defined to calculate the information loss between two arrays using the mean squared differences and a scaling factor.\n",
    "Information loss is calculated for each column, aggregated, and then the total information loss is printed:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a141aa81ac401563"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read the CSV files\n",
    "\n",
    "original_data = pd.read_csv(\"athletes.csv\")\n",
    "anonymized_data = pd.read_csv(\"athletes_anonyzmized.csv\")\n",
    "\n",
    "# Columns to calculate information loss\n",
    "columns_to_compare = ['pullups', 'helen', 'grace', 'filthy50', 'fgonebad', 'run400', 'run5k', 'candj', 'snatch', 'deadlift', 'backsq']\n",
    "\n",
    "# Calculate Information Loss\n",
    "def calculate_information_loss(x, y, S):\n",
    "    return (x - y) / np.sqrt(2 * S)\n",
    "\n",
    "total_information_loss = 0\n",
    "n = len(original_data)  # Assuming both datasets have the same number of rows\n",
    "p = len(columns_to_compare)  # Number of columns to compare\n",
    "\n",
    "for column in columns_to_compare:\n",
    "    x = original_data[column]\n",
    "    y = anonymized_data[column]\n",
    "    S = np.mean((x - y) ** 2)  # Variance of the differences in the column\n",
    "\n",
    "    information_loss = np.sum(calculate_information_loss(x, y, S)) / (p * n)\n",
    "    total_information_loss += information_loss\n",
    "\n",
    "print(\"Total Information Loss:\", total_information_loss)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-21T14:37:00.433301Z"
    }
   },
   "id": "66c50d3e82868de8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-21T14:37:00.436595Z"
    }
   },
   "id": "a9b38097fd44d7be"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
