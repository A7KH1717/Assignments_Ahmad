{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2 Anonymising your dataset\n",
    "Goals: The goal of k-anonymity is to modify a dataset such that any given record cannot be distinguished from at least k−1 other records regarding certain \"quasi-identifier\" attributes.\n",
    "\n",
    "quasi-identifiers: 'region', 'gender', 'age', 'height', 'weight', 'eat', 'schedule', 'howlong'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22b781a2e32b01fb"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "   athlete_id           name               region          team  \\\n0        2554      Pj Ablang           South West   Double Edge   \n1        3517  Derek Abdella                                NaN   \n2        4691            NaN                                NaN   \n3        5164    Abo Brandon  Southern California  LAX CrossFit   \n4        5286    Bryce Abbey                                NaN   \n\n              affiliate gender   age  height  weight   fran  ...  deadlift  \\\n0  Double Edge CrossFit   Male  24.0    70.0   166.0    NaN  ...     400.0   \n1                   NaN   Male  42.0    70.0   190.0    NaN  ...       NaN   \n2                   NaN          0.0     0.0     0.0    NaN  ...       NaN   \n3          LAX CrossFit   Male  40.0    67.0     0.0  211.0  ...     375.0   \n4                   NaN   Male  32.0    65.0   149.0  206.0  ...       NaN   \n\n   backsq  pullups                                                eat  \\\n0   305.0      NaN                                                NaN   \n1     NaN      NaN                                                NaN   \n2     NaN      NaN                                                NaN   \n3   325.0     25.0               I eat 1-3 full cheat meals per week|   \n4   325.0     50.0  I eat quality foods but don't measure the amount|   \n\n                                               train  \\\n0  I workout mostly at a CrossFit Affiliate|I hav...   \n1  I have a coach who determines my programming|I...   \n2                                                NaN   \n3  I workout mostly at a CrossFit Affiliate|I hav...   \n4  I workout mostly at a CrossFit Affiliate|I inc...   \n\n                                          background  \\\n0  I played youth or high school level sports|I r...   \n1        I played youth or high school level sports|   \n2                                                NaN   \n3        I played youth or high school level sports|   \n4                           I played college sports|   \n\n                                          experience  \\\n0  I began CrossFit with a coach (e.g. at an affi...   \n1  I began CrossFit with a coach (e.g. at an affi...   \n2                                                NaN   \n3  I began CrossFit by trying it alone (without a...   \n4  I began CrossFit by trying it alone (without a...   \n\n                                            schedule     howlong  \\\n0         I do multiple workouts in a day 2x a week|   4+ years|   \n1         I do multiple workouts in a day 2x a week|   4+ years|   \n2                                                NaN         NaN   \n3                 I usually only do 1 workout a day|   4+ years|   \n4  I usually only do 1 workout a day|I strictly s...  1-2 years|   \n\n   retrieved_datetime  \n0                 NaN  \n1                 NaN  \n2                 NaN  \n3                 NaN  \n4                 NaN  \n\n[5 rows x 28 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>athlete_id</th>\n      <th>name</th>\n      <th>region</th>\n      <th>team</th>\n      <th>affiliate</th>\n      <th>gender</th>\n      <th>age</th>\n      <th>height</th>\n      <th>weight</th>\n      <th>fran</th>\n      <th>...</th>\n      <th>deadlift</th>\n      <th>backsq</th>\n      <th>pullups</th>\n      <th>eat</th>\n      <th>train</th>\n      <th>background</th>\n      <th>experience</th>\n      <th>schedule</th>\n      <th>howlong</th>\n      <th>retrieved_datetime</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2554</td>\n      <td>Pj Ablang</td>\n      <td>South West</td>\n      <td>Double Edge</td>\n      <td>Double Edge CrossFit</td>\n      <td>Male</td>\n      <td>24.0</td>\n      <td>70.0</td>\n      <td>166.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>400.0</td>\n      <td>305.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>I workout mostly at a CrossFit Affiliate|I hav...</td>\n      <td>I played youth or high school level sports|I r...</td>\n      <td>I began CrossFit with a coach (e.g. at an affi...</td>\n      <td>I do multiple workouts in a day 2x a week|</td>\n      <td>4+ years|</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3517</td>\n      <td>Derek Abdella</td>\n      <td></td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Male</td>\n      <td>42.0</td>\n      <td>70.0</td>\n      <td>190.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>I have a coach who determines my programming|I...</td>\n      <td>I played youth or high school level sports|</td>\n      <td>I began CrossFit with a coach (e.g. at an affi...</td>\n      <td>I do multiple workouts in a day 2x a week|</td>\n      <td>4+ years|</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4691</td>\n      <td>NaN</td>\n      <td></td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td></td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5164</td>\n      <td>Abo Brandon</td>\n      <td>Southern California</td>\n      <td>LAX CrossFit</td>\n      <td>LAX CrossFit</td>\n      <td>Male</td>\n      <td>40.0</td>\n      <td>67.0</td>\n      <td>0.0</td>\n      <td>211.0</td>\n      <td>...</td>\n      <td>375.0</td>\n      <td>325.0</td>\n      <td>25.0</td>\n      <td>I eat 1-3 full cheat meals per week|</td>\n      <td>I workout mostly at a CrossFit Affiliate|I hav...</td>\n      <td>I played youth or high school level sports|</td>\n      <td>I began CrossFit by trying it alone (without a...</td>\n      <td>I usually only do 1 workout a day|</td>\n      <td>4+ years|</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5286</td>\n      <td>Bryce Abbey</td>\n      <td></td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Male</td>\n      <td>32.0</td>\n      <td>65.0</td>\n      <td>149.0</td>\n      <td>206.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>325.0</td>\n      <td>50.0</td>\n      <td>I eat quality foods but don't measure the amount|</td>\n      <td>I workout mostly at a CrossFit Affiliate|I inc...</td>\n      <td>I played college sports|</td>\n      <td>I began CrossFit by trying it alone (without a...</td>\n      <td>I usually only do 1 workout a day|I strictly s...</td>\n      <td>1-2 years|</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 28 columns</p>\n</div>"
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"kleinerTest.csv\", index_col=False, low_memory=False)\n",
    "\n",
    "df['age'].fillna(0, inplace=True)\n",
    "df['height'].fillna(0, inplace=True)\n",
    "df['weight'].fillna(0, inplace=True)\n",
    "\n",
    "df['region'].fillna('', inplace=True)\n",
    "df['gender'].fillna('', inplace=True)\n",
    "\n",
    "df.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T12:51:28.827442900Z",
     "start_time": "2024-01-11T12:51:28.784929400Z"
    }
   },
   "id": "6f02b8c8ecab030e",
   "execution_count": 543
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "outputs": [],
   "source": [
    "def get_spans(df, partition, scale=None):\n",
    "    \"\"\"\n",
    "    Calculates and returns the spans (range of values) for each column in a specified partition of a dataframe, with\n",
    "    an option to scale these spans by provided values.\n",
    "\n",
    "    :param        df: the dataframe for which to calculate the spans\n",
    "    :param partition: the partition for which to calculate the spans\n",
    "    :param     scale: if given, the spans of each column will be divided\n",
    "                      by the value in scale for that column\n",
    "    :returns        : The spans of all columns in the partition\n",
    "    \"\"\"\n",
    "    spans = {}\n",
    "    for feature_column in quasi_identifiers:\n",
    "        if feature_column in categorical:\n",
    "            span = len(df[feature_column][partition].unique())\n",
    "        else:\n",
    "            span = df[feature_column][partition].max() - df[feature_column][partition].min()\n",
    "        if scale is not None:\n",
    "            span = span / scale[feature_column]\n",
    "        spans[feature_column] = span\n",
    "    return spans"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T12:51:28.828434400Z",
     "start_time": "2024-01-11T12:51:28.804197900Z"
    }
   },
   "id": "6c70412e40d9d7fb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def split(df, partition, column):\n",
    "    \"\"\"\n",
    "    Divides a specified partition of a dataframe into two parts based on the median or unique values of a given column,\n",
    "    returning a tuple with the indices of these two parts.\n",
    "\n",
    "    :param        df: The dataframe to split\n",
    "    :param partition: The partition to split\n",
    "    :param    column: The column along which to split\n",
    "    :returns        : A tuple containing a split of the original partition\n",
    "    \"\"\"\n",
    "    dfp = df[column][partition]\n",
    "    if column in categorical:\n",
    "        values = dfp.unique()\n",
    "        lv = set(values[:len(values) // 2])\n",
    "        rv = set(values[len(values) // 2:])\n",
    "        return dfp.index[dfp.isin(lv)], dfp.index[dfp.isin(rv)]\n",
    "    else:\n",
    "        median = dfp.median()\n",
    "        dfl = dfp.index[dfp < median]\n",
    "        dfr = dfp.index[dfp >= median]\n",
    "        return (dfl, dfr)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T12:51:28.828434400Z",
     "start_time": "2024-01-11T12:51:28.809113700Z"
    }
   },
   "id": "91f3144e071e27cb",
   "execution_count": 545
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def is_k_anonymous(df, partition, sensitive_column, k=1):\n",
    "    \"\"\"\n",
    "    Checks if a partition is k-anonymous by comparing its amount of entries with the required (k).\n",
    "\n",
    "    :param               df: The dataframe on which to check the partition.\n",
    "    :param        partition: The partition of the dataframe to check.\n",
    "    :param sensitive_column: The name of the sensitive column\n",
    "    :param                k: The desired k\n",
    "    :returns               : True if the partition is valid according to our k-anonymity criteria, False otherwise.\n",
    "    \"\"\"\n",
    "    if len(partition) < k:\n",
    "        return False\n",
    "    return True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T12:51:28.851885200Z",
     "start_time": "2024-01-11T12:51:28.831481Z"
    }
   },
   "id": "b9a2b33d03f26ba2",
   "execution_count": 546
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def partition_dataset(df, feature_columns, sensitive_column, scale, is_valid):\n",
    "    \"\"\"\n",
    "    Partitions a dataframe into valid subsets based on specified feature columns, a sensitive column, and span scales,\n",
    "    using a validity function to ensure each partition meets certain criteria.\n",
    "\n",
    "    :param               df: The dataframe to be partitioned.\n",
    "    :param  feature_columns: A list of column names along which to partition the dataset.\n",
    "    :param sensitive_column: The name of the sensitive column (to be passed on to the is_valid function)\n",
    "    :param            scale: The column spans as generated before.\n",
    "    :param         is_valid: A function that takes a dataframe and a partition and returns True if the partition is valid.\n",
    "    :returns               : A list of valid partitions that cover the entire dataframe.\n",
    "    \"\"\"\n",
    "    finished_partitions = []\n",
    "    partitions = [df.index]\n",
    "    while partitions:\n",
    "        partition = partitions.pop(0)\n",
    "        spans = get_spans(df[feature_columns], partition, scale)\n",
    "        for column, span in sorted(spans.items(), key=lambda x: -x[1]):\n",
    "            lp, rp = split(df, partition, column)\n",
    "            if not is_valid(df, lp, sensitive_column) or not is_valid(df, rp, sensitive_column):\n",
    "                continue\n",
    "            partitions.extend((lp, rp))\n",
    "            break\n",
    "        else:\n",
    "            finished_partitions.append(partition)\n",
    "    return finished_partitions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T12:51:28.869464400Z",
     "start_time": "2024-01-11T12:51:28.836805200Z"
    }
   },
   "id": "45ea8668dea21938",
   "execution_count": 547
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def agg_categorical_column(series):\n",
    "    \"\"\"\n",
    "    Aggregates the values of a series with categorical values by concatenating them.\n",
    "\n",
    "    :param           series: A series of categorical values that need to be aggregated.\n",
    "    :returns               : A string with all the values in the series joined with a ',' (comma).\n",
    "    \"\"\"\n",
    "    series = set(series.astype(str))\n",
    "    return ','.join(series)\n",
    "    #return [','.join(series)]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T12:51:28.900646800Z",
     "start_time": "2024-01-11T12:51:28.846623100Z"
    }
   },
   "id": "d260d0e832101ffd",
   "execution_count": 548
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def agg_numerical_column(series):\n",
    "    return series.mean()\n",
    "    #return [series.mean()]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T12:51:28.944068600Z",
     "start_time": "2024-01-11T12:51:28.859577700Z"
    }
   },
   "id": "1f48f0e16c8b2940",
   "execution_count": 549
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def build_anonymized_dataset(df, partitions, feature_columns, sensitive_columns,\n",
    "                                                  max_partitions=None):\n",
    "    \"\"\"\n",
    "    Constructs an anonymized dataset by aggregating feature columns and sensitive columns separately for each partition.\n",
    "\n",
    "    :param                df: The dataframe to be anonymized.\n",
    "    :param        partitions: A list of indices for each partition of the dataframe.\n",
    "    :param   feature_columns: A list of feature column names to aggregate.\n",
    "    :param sensitive_columns: A list of sensitive column names to aggregate.\n",
    "    :param    max_partitions: Optional, maximum number of partitions to process.\n",
    "    :returns                : An anonymized dataframe with aggregated feature and sensitive columns.\n",
    "    \"\"\"\n",
    "    aggregations = {}\n",
    "    for column in feature_columns:\n",
    "        if column in categorical:\n",
    "            aggregations[column] = agg_categorical_column\n",
    "        else:\n",
    "            aggregations[column] = agg_numerical_column\n",
    "    rows = []\n",
    "    for i, partition in enumerate(partitions):\n",
    "        if i % 100 == 1:\n",
    "            print(\"Finished {} partitions...\".format(i))\n",
    "        if max_partitions is not None and i > max_partitions:\n",
    "            break\n",
    "        grouped_columns = df.loc[partition].agg(aggregations, squeeze=False)\n",
    "        values = grouped_columns.to_dict()\n",
    "        # Iterate through each sensitive column and aggregate counts\n",
    "        for sensitive_column in sensitive_columns:\n",
    "            sensitive_counts = df.loc[partition].groupby(sensitive_column).agg({sensitive_column: 'count'})\n",
    "            for sensitive_value, count in sensitive_counts[sensitive_column].items():\n",
    "                if count == 0:\n",
    "                    continue\n",
    "                sensitive_values = values.copy()\n",
    "                sensitive_values.update({\n",
    "                    sensitive_column: sensitive_value,\n",
    "                    'count': count,\n",
    "                })\n",
    "                rows.append(sensitive_values)\n",
    "    return pd.DataFrame(rows)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T12:51:28.946076200Z",
     "start_time": "2024-01-11T12:51:28.874699200Z"
    }
   },
   "id": "c4cf30a6fb09d064",
   "execution_count": 550
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "categorical = {'schedule', 'howlong', 'region', 'gender', 'eat'}\n",
    "\n",
    "# we apply our partitioning method to two columns of our dataset, using \"income\" as the sensitive attribute\n",
    "for name in categorical:\n",
    "    df[name] = df[name].astype('category')\n",
    "# Obtain the spans for each column in the dataframe\n",
    "# quasi-identifiers that should be taken into acount\n",
    "\n",
    "quasi_identifiers = ['region', 'gender', 'age', 'height', 'weight', 'eat', 'schedule', 'howlong']\n",
    "# sensitive-values that should be taken into account\n",
    "sensitive_columns = ['athlete_id', 'fran', 'helen', 'grace', 'filthy50', 'fgonebad', 'run400', 'run5k', 'candj', 'snatch', 'deadlift',\n",
    "                     'backsq', 'pullups', 'retrieved_datetime']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T12:51:28.980793600Z",
     "start_time": "2024-01-11T12:51:28.949891700Z"
    }
   },
   "id": "e92b677b7074e723",
   "execution_count": 551
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "full_spans = get_spans(df, df.index)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T12:51:28.981793900Z",
     "start_time": "2024-01-11T12:51:28.956987800Z"
    }
   },
   "id": "5190fc885bf63bf1",
   "execution_count": 552
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "64"
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finished_partitions = partition_dataset(df, quasi_identifiers, sensitive_columns, full_spans, is_k_anonymous)\n",
    "len(finished_partitions)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T12:51:29.778736700Z",
     "start_time": "2024-01-11T12:51:28.970783800Z"
    }
   },
   "id": "3904e62d591e3ec3",
   "execution_count": 553
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 1 partitions...\n"
     ]
    }
   ],
   "source": [
    "dfn = build_anonymized_dataset(df, finished_partitions, quasi_identifiers, sensitive_columns)\n",
    "# we sort the resulting dataframe using the feature columns and the sensitive attribute\n",
    "#dfn.sort_values()\n",
    "\n",
    "dfn.to_csv(\"temp.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T12:51:30.682135700Z",
     "start_time": "2024-01-11T12:51:29.779744800Z"
    }
   },
   "id": "9b0bd1ba37772d37",
   "execution_count": 554
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
