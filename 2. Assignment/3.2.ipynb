{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2 Anonymising your dataset\n",
    "Goals: The goal of k-anonymity is to modify a dataset such that any given record cannot be distinguished from at least kâˆ’1 other records regarding certain \"quasi-identifier\" attributes.\n",
    "\n",
    "quasi-identifiers: 'region', 'gender', 'age', 'height', 'weight', 'eat', 'schedule', 'howlong'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22b781a2e32b01fb"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "def get_spans(df, partition, scale=None):\n",
    "    \"\"\"\n",
    "    Calculates and returns the spans (range of values) for each column in a specified partition of a dataframe, with\n",
    "    an option to scale these spans by provided values.\n",
    "\n",
    "    :param        df: the dataframe for which to calculate the spans\n",
    "    :param partition: the partition for which to calculate the spans\n",
    "    :param     scale: if given, the spans of each column will be divided\n",
    "                      by the value in scale for that column\n",
    "    :returns        : The spans of all columns in the partition\n",
    "    \"\"\"\n",
    "    spans = {}\n",
    "    for feature_column in quasi_identifiers:\n",
    "        if feature_column in categorical:\n",
    "            span = len(df[feature_column][partition].unique())\n",
    "        else:\n",
    "            span = df[feature_column][partition].max() - df[feature_column][partition].min()\n",
    "        if scale is not None:\n",
    "            span = span / scale[feature_column]\n",
    "        spans[feature_column] = span\n",
    "    return spans"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T10:30:52.646580Z",
     "start_time": "2024-01-11T10:30:52.642647Z"
    }
   },
   "id": "6c70412e40d9d7fb"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "{'region': 18,\n 'gender': 4,\n 'howlong': 31,\n 'eat': 48,\n 'weight': 20174.0,\n 'schedule': 135,\n 'age': 112.0,\n 'height': 8388607.0}"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_spans = get_spans(df, df.index)\n",
    "full_spans"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T10:30:52.747978Z",
     "start_time": "2024-01-11T10:30:52.645811Z"
    }
   },
   "id": "91f3144e071e27cb"
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "def split(df, partition, column):\n",
    "    \"\"\"\n",
    "    Divides a specified partition of a dataframe into two parts based on the median or unique values of a given column,\n",
    "    returning a tuple with the indices of these two parts.\n",
    "\n",
    "    :param        df: The dataframe to split\n",
    "    :param partition: The partition to split\n",
    "    :param    column: The column along which to split\n",
    "    :returns        : A tuple containing a split of the original partition\n",
    "    \"\"\"\n",
    "    dfp = df[column][partition]\n",
    "    if column in categorical:\n",
    "        values = dfp.unique()\n",
    "        lv = set(values[:len(values) // 2])\n",
    "        rv = set(values[len(values) // 2:])\n",
    "        return dfp.index[dfp.isin(lv)], dfp.index[dfp.isin(rv)]\n",
    "    else:\n",
    "        median = dfp.median()\n",
    "        dfl = dfp.index[dfp < median]\n",
    "        dfr = dfp.index[dfp >= median]\n",
    "        return (dfl, dfr)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T10:30:52.748318Z",
     "start_time": "2024-01-11T10:30:52.721438Z"
    }
   },
   "id": "b9a2b33d03f26ba2"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "def is_k_anonymous(df, partition, sensitive_column, k=3):\n",
    "    \"\"\"\n",
    "    Checks if a partition is k-anonymous by comparing its amount of entries with the required (k).\n",
    "\n",
    "    :param               df: The dataframe on which to check the partition.\n",
    "    :param        partition: The partition of the dataframe to check.\n",
    "    :param sensitive_column: The name of the sensitive column\n",
    "    :param                k: The desired k\n",
    "    :returns               : True if the partition is valid according to our k-anonymity criteria, False otherwise.\n",
    "    \"\"\"\n",
    "    if len(partition) < k:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def partition_dataset(df, feature_columns, sensitive_column, scale, is_valid):\n",
    "    \"\"\"\n",
    "    Partitions a dataframe into valid subsets based on specified feature columns, a sensitive column, and span scales,\n",
    "    using a validity function to ensure each partition meets certain criteria.\n",
    "\n",
    "    :param               df: The dataframe to be partitioned.\n",
    "    :param  feature_columns: A list of column names along which to partition the dataset.\n",
    "    :param sensitive_column: The name of the sensitive column (to be passed on to the is_valid function)\n",
    "    :param            scale: The column spans as generated before.\n",
    "    :param         is_valid: A function that takes a dataframe and a partition and returns True if the partition is valid.\n",
    "    :returns               : A list of valid partitions that cover the entire dataframe.\n",
    "    \"\"\"\n",
    "    finished_partitions = []\n",
    "    partitions = [df.index]\n",
    "    while partitions:\n",
    "        partition = partitions.pop(0)\n",
    "        spans = get_spans(df[feature_columns], partition, scale)\n",
    "        for column, span in sorted(spans.items(), key=lambda x: -x[1]):\n",
    "            lp, rp = split(df, partition, column)\n",
    "            if not is_valid(df, lp, sensitive_column) or not is_valid(df, rp, sensitive_column):\n",
    "                continue\n",
    "            partitions.extend((lp, rp))\n",
    "            break\n",
    "        else:\n",
    "            finished_partitions.append(partition)\n",
    "    return finished_partitions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T10:30:52.750382Z",
     "start_time": "2024-01-11T10:30:52.727325Z"
    }
   },
   "id": "addf10f0917d6570"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'region'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py:3790\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3789\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3790\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3791\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32mindex.pyx:152\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mindex.pyx:181\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'region'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[56], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m feature_columns \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mage\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mheight\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m      3\u001B[0m sensitive_column \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mathlete_id\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfran\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhelen\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgrace\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfilthy50\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfgonebad\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrun400\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrun5k\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcandj\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msnatch\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdeadlift\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbacksq\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpullups\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m----> 4\u001B[0m finished_partitions \u001B[38;5;241m=\u001B[39m \u001B[43mpartition_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeature_columns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msensitive_column\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfull_spans\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_k_anonymous\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[55], line 26\u001B[0m, in \u001B[0;36mpartition_dataset\u001B[0;34m(df, feature_columns, sensitive_column, scale, is_valid)\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m partitions:\n\u001B[1;32m     25\u001B[0m     partition \u001B[38;5;241m=\u001B[39m partitions\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m---> 26\u001B[0m     spans \u001B[38;5;241m=\u001B[39m \u001B[43mget_spans\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[43mfeature_columns\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpartition\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscale\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     27\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m column, span \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28msorted\u001B[39m(spans\u001B[38;5;241m.\u001B[39mitems(), key\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m x:\u001B[38;5;241m-\u001B[39mx[\u001B[38;5;241m1\u001B[39m]):\n\u001B[1;32m     28\u001B[0m         lp, rp \u001B[38;5;241m=\u001B[39m split(df, partition, column)\n",
      "Cell \u001B[0;32mIn[52], line 12\u001B[0m, in \u001B[0;36mget_spans\u001B[0;34m(df, partition, scale)\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m column \u001B[38;5;129;01min\u001B[39;00m quasi:\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m column \u001B[38;5;129;01min\u001B[39;00m categorical:\n\u001B[0;32m---> 12\u001B[0m         span \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[43mcolumn\u001B[49m\u001B[43m]\u001B[49m[partition]\u001B[38;5;241m.\u001B[39munique())\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     14\u001B[0m         span \u001B[38;5;241m=\u001B[39m df[column][partition]\u001B[38;5;241m.\u001B[39mmax()\u001B[38;5;241m-\u001B[39mdf[column][partition]\u001B[38;5;241m.\u001B[39mmin()\n",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/frame.py:3893\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3891\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   3892\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 3893\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3894\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   3895\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py:3797\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3792\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(casted_key, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[1;32m   3793\u001B[0m         \u001B[38;5;28misinstance\u001B[39m(casted_key, abc\u001B[38;5;241m.\u001B[39mIterable)\n\u001B[1;32m   3794\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m casted_key)\n\u001B[1;32m   3795\u001B[0m     ):\n\u001B[1;32m   3796\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[0;32m-> 3797\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3798\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3799\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3800\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3801\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[1;32m   3802\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'region'"
     ]
    }
   ],
   "source": [
    "def agg_categorical_column(series):\n",
    "    \"\"\"\n",
    "    Aggregates the values of a series with categorical values by concatenating them.\n",
    "\n",
    "    :param           series: A series of categorical values that need to be aggregated.\n",
    "    :returns               : A string with all the values in the series joined with a ',' (comma).\n",
    "    \"\"\"\n",
    "    series = set(series.astype(str))\n",
    "    return [','.join(series)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T10:30:52.789081Z",
     "start_time": "2024-01-11T10:30:52.731190Z"
    }
   },
   "id": "b47f3d894f9cb78f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def agg_numerical_column(series):\n",
    "    \"\"\"\n",
    "    Aggregates the values of a series with numerical values by taking their mean.\n",
    "\n",
    "    :param           series: A series of numerical values that need to be aggregated.\n",
    "    :returns               : Mean value of the values in the series.\n",
    "    \"\"\"\n",
    "    print(series)\n",
    "    return [series.mean()]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-11T10:30:52.785396Z"
    }
   },
   "id": "b297152afcd1c20e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
