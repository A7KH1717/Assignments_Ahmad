{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Assignment #2-3: Anonymisation\n",
    "- Dataset: Crossfit [Daset](https://data.world/bgadoci/crossfit-data) (In this assignment only the athletes file was used) \n",
    "- Credits: Dataset was put together by Sam Swift\n",
    "- ToDo: To run the jupyter notebook the requirements.txt need be installed (`pip install -r requirements.txt`)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read csv as dataframe\n",
    "df = pd.read_csv(\"athletes.csv\", low_memory=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T10:57:20.077049Z",
     "start_time": "2024-01-10T10:57:18.833475Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## First Step: Revisit the data set to remind ourselves what we are working with\n",
    "- For a better understanding of the structure of the dataset , we display the attribute values\n",
    "    - What columns does the dataset contain and in what format are the attribute values?\n",
    "        - Therefore, each column and the first value of each column (which is not empty or Null) is printed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: 'athlete_id', Example Data: 2554.0\n",
      "Column: 'name', Example Data: Pj Ablang\n",
      "Column: 'region', Example Data: South West\n",
      "Column: 'team', Example Data: Double Edge\n",
      "Column: 'affiliate', Example Data: Double Edge CrossFit\n",
      "Column: 'gender', Example Data: Male\n",
      "Column: 'age', Example Data: 24.0\n",
      "Column: 'height', Example Data: 70.0\n",
      "Column: 'weight', Example Data: 166.0\n",
      "Column: 'fran', Example Data: 211.0\n",
      "Column: 'helen', Example Data: 645.0\n",
      "Column: 'grace', Example Data: 300.0\n",
      "Column: 'filthy50', Example Data: 1053.0\n",
      "Column: 'fgonebad', Example Data: 0.0\n",
      "Column: 'run400', Example Data: 61.0\n",
      "Column: 'run5k', Example Data: 1081.0\n",
      "Column: 'candj', Example Data: 220.0\n",
      "Column: 'snatch', Example Data: 200.0\n",
      "Column: 'deadlift', Example Data: 400.0\n",
      "Column: 'backsq', Example Data: 305.0\n",
      "Column: 'pullups', Example Data: 25.0\n",
      "Column: 'eat', Example Data: I eat 1-3 full cheat meals per week|\n",
      "Column: 'train', Example Data: I workout mostly at a CrossFit Affiliate|I have a coach who determines my programming|I record my workouts|\n",
      "Column: 'background', Example Data: I played youth or high school level sports|I regularly play recreational sports|\n",
      "Column: 'experience', Example Data: I began CrossFit with a coach (e.g. at an affiliate)|I have attended one or more specialty courses|I have had a life changing experience due to CrossFit|\n",
      "Column: 'schedule', Example Data: I do multiple workouts in a day 2x a week|\n",
      "Column: 'howlong', Example Data: 4+ years|\n",
      "Column: 'retrieved_datetime', Example Data: 2015-03-01 22:49:18\n"
     ]
    }
   ],
   "source": [
    "def get_first_not_not_empty_value(df_column):\n",
    "    return df_column.dropna().iloc[0] if not df_column.dropna().empty else None\n",
    "\n",
    "# Iterate each column \n",
    "for column in df.columns:\n",
    "    first_value = get_first_not_not_empty_value(df[column])\n",
    "    print(f\"Column: '{column}', Example Data: {first_value}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T10:57:20.360039Z",
     "start_time": "2024-01-10T10:57:20.077285Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1 Anonymisation: Bare Bones – 10 marks\n",
    "Goals: The goal of k-anonymity is to modify a dataset such that any given record cannot be distinguished from at least k−1 other records regarding certain \"quasi-identifier\" attributes. \n",
    "\n",
    "### Algorithm Steps: \n",
    "1. Identify the direct identifier attributes in the data set.\n",
    "2. Identify the quasi-identifiers attributes in the dataset.\n",
    "3. Apply k-anonymity: Choose a value for k (size of the groups of indistinguishable records)\n",
    "4. Use Generalization and Suppression as the transformation methods to transform quasi-identifiers\n",
    "5. Ensure that there are at least k records for each combination of quasi-identifiers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1. Identify  direct identifier attributes\n",
    "- By inspecting the different columns and the data format, several attributes which have the potential to contain explicit personally identifiable information can be identified\n",
    "    - `athelete_id`\n",
    "        -  This really depends on the usage of this id! Considerations to take into account are: \n",
    "            - Is the `athlete_id` only used as an internal id of this dataset or does it maybe even refer to an official id?\n",
    "            - Are there other datasets available which may have a similar source to this dataset? Thus, these other datasets may use the same `athlete_id`\n",
    "    - `name`\n",
    "        - The name allows to identify an individual\n",
    "    - `team`\n",
    "        - Depending on the size of the team, this could allow to identify a specific athlete\n",
    "    - `affiliate` \n",
    "        - Depending on the affiliate and the amount of contracted athletes, this could allow to identify an individual\n",
    "    - All stats of the athletes\n",
    "        - If an athlete has really remarkable stats (maybe even a world record in a category), this could allow to identify the individual\n",
    "    - `train` \n",
    "        - If an athlete has a special and famous training routine, this could allow to identify him\n",
    "    - `background`\n",
    "        - If an athlete has a famous background or mentions names, this could allow to identify him\n",
    "    - `experience`\n",
    "        - If an athlete mentions concrete information about his experience (e.g. name of current coach), this could allow to identify him\n",
    "\n",
    "-> As can be seen, all columns could potentially contain outliers which could be then used to identify an individual. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2. Identify the quasi-identifiers attributes in the dataset\n",
    "- In this step, we use the following script to search for any attributes qualifying as a quasi-identifiers not flagged as PII in the step before. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Potential Quasi-Identifiers: ['region', 'gender', 'age', 'height', 'weight', 'eat', 'schedule', 'howlong', 'retrieved_datetime']\n"
     ]
    }
   ],
   "source": [
    "# identify potential quasi-identifiers\n",
    "def identify_quasi_identifiers(dataframe, sensitive_columns):\n",
    "    quasi_identifiers = []\n",
    "    for column in dataframe.columns:\n",
    "        # Skip sensitive attributes\n",
    "        if column in sensitive_columns:\n",
    "            continue\n",
    "        \n",
    "        unique_count = dataframe[column].nunique()\n",
    "        # Assume a column could be a quasi-identifier if it's not unique for each record\n",
    "        # but has a high number of unique values.\n",
    "        if 1 < unique_count < len(dataframe):\n",
    "            quasi_identifiers.append(column)\n",
    "    \n",
    "    return quasi_identifiers\n",
    "\n",
    "# column names we know are PII\n",
    "sensitive_columns = ['athlete_id', 'name', 'team', 'affiliate', 'train', 'background', 'experience', 'fran', 'helen',  'grace', 'filthy50', 'fgonebad', 'run400', 'run5k', 'candj', 'snatch', 'deadlift', 'backsq', 'pullups']\n",
    "\n",
    "# Identify potential quasi-identifiers\n",
    "potential_quasi_identifiers = identify_quasi_identifiers(df, sensitive_columns)\n",
    "print(\"Potential Quasi-Identifiers:\", potential_quasi_identifiers)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T10:57:20.407168Z",
     "start_time": "2024-01-10T10:57:20.361760Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3. Apply k-anonymity: Choose a value for k\n",
    "- In this step we choose a value for k. \n",
    "- For example if we choose k = 3, then each combination of quasi-identifier values should apply to at least three records in the given dataset\n",
    "- a higher k value strengthens privacy by making re-identification more difficult, it also reduces the utility of the data by increasing information loss. \n",
    "- The choice of k thus represents a trade-off between privacy and utility that must be considered in the context of how the data will be used."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4. Use Generalization, Aggregation and Suppression as the transformation methods\n",
    "- Some data exploration has been done in #Assignment 1 already, so the intervals for different attributes and replacement values can be recycled. Some exploration must be done on top of it.\n",
    "- The attribute 'retrieved_datetime' can be removed, since all the entries are empty. Also, we standardize empty values.\n",
    "- The quasi-identifiers 'age', 'height', 'weight' will be anonymized using aggregation\n",
    "- Every attribute occuring less than 50 times in the entire dataset will be suppressed\n",
    "- The 'regions' will be mapped to the 7 continents\n",
    "- The 'schedule' attribute will be mapped to meaningful strings\n",
    "- The 'eat' attribute will be mapped to 4 different categories"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "outputs": [],
   "source": [
    "#drop the 'retrieved_datetime' column\n",
    "df = df.drop(columns=['retrieved_datetime'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T10:57:20.457582Z",
     "start_time": "2024-01-10T10:57:20.406297Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "outputs": [],
   "source": [
    "# Iterate over all columns in the DataFrame\n",
    "for column in df.columns:\n",
    "    # Replace empty strings with 'NA' in the column\n",
    "    df[column] = df[column].replace({'': 'NA'})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T10:57:20.698663Z",
     "start_time": "2024-01-10T10:57:20.454738Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Now, the aggregation\n",
    "- Using aggregation for attributes like 'age', 'weight' and 'height' makes sense in this context.\n",
    "- This provides a more concise representation of the data distribution while enabling to achieve k-anonymity."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "outputs": [],
   "source": [
    "# Aggregate age, height and weight\n",
    "bins_age = [0, 18, 30, 45, 60, 100]\n",
    "labels_age = ['0-18', '19-30', '31-45', '46-60', '60+']\n",
    "\n",
    "bins_height = [0, 20, 40, 60, 70, 80, 90]\n",
    "labels_height = ['0-20', '20-40', '40-60', '60-70', '70-80', '81+']\n",
    "\n",
    "bins_weight = [0, 159, 169, 179, 189, 199, 220]\n",
    "labels_weight = ['0-159', '160-169', '170-179', '180-189', '190-199', '200+']\n",
    "\n",
    "# Apply binning\n",
    "df['age'] = pd.cut(df['age'], bins=bins_age, labels=labels_age)\n",
    "df['height'] = pd.cut(df['height'], bins=bins_height, labels=labels_height)\n",
    "df['weight'] = pd.cut(df['weight'], bins=bins_weight, labels=labels_weight)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T10:57:20.734112Z",
     "start_time": "2024-01-10T10:57:20.700216Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Now, the suppression\n",
    "- By suppressing these rare occurrences, we reduce the risk of someone being able to link the data back to a specific individual"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "outputs": [],
   "source": [
    "# List of columns to apply the suppression\n",
    "columns_to_suppress = ['region', 'gender', 'age', 'height', 'weight', 'eat', 'schedule', 'howlong']\n",
    "\n",
    "for column in columns_to_suppress:\n",
    "    # Counting the frequency of each unique value in the column\n",
    "    value_counts = df[column].value_counts()\n",
    "\n",
    "    # Identifying values that occur less than 20 times\n",
    "    values_to_remove = value_counts[value_counts < 100].index\n",
    "\n",
    "    # Removing rows with these values\n",
    "    df = df[~df[column].isin(values_to_remove)]\n",
    "\n",
    "# After this loop, df contains your DataFrame with rare values removed in each specified column"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T10:57:21.223351Z",
     "start_time": "2024-01-10T10:57:20.741437Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Now, the mapping: \n",
    "- The goal is to create broader categories that encapsulate the essence of the individual schedules without being overly specific.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique regions: ['South West' nan 'Southern California' 'South Central' 'Central East'\n",
      " 'Europe' 'North East' 'Africa' 'South East' 'Australia'\n",
      " 'Northern California' 'Latin America' 'Canada East' 'North Central'\n",
      " 'North West' 'Mid Atlantic' 'Canada West' 'Asia']\n"
     ]
    }
   ],
   "source": [
    "#Data exploration to map the regions in a meaningful way\n",
    "unique_regions = df['region'].unique()\n",
    "print(\"Unique regions:\", unique_regions)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T10:57:21.229181Z",
     "start_time": "2024-01-10T10:57:21.227101Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "outputs": [],
   "source": [
    "# mapping of regions to continents\n",
    "region_to_continent = {\n",
    "    'South West': 'North America',\n",
    "    'Southern California': 'North America',\n",
    "    'South Central': 'North America',\n",
    "    'Central East': 'North America',\n",
    "    'Europe': 'Europe',\n",
    "    'North East': 'North America',\n",
    "    'Africa': 'Africa',\n",
    "    'South East': 'North America',\n",
    "    'Australia': 'Oceania',\n",
    "    'Northern California': 'North America',\n",
    "    'Latin America': 'South America',\n",
    "    'Canada East': 'North America',\n",
    "    'North Central': 'North America',\n",
    "    'North West': 'North America',\n",
    "    'Mid Atlantic': 'North America',\n",
    "    'Canada West': 'North America',\n",
    "    'Asia': 'Asia',\n",
    "    'NA': 'NA'  # Preserving 'NA' as is\n",
    "}\n",
    "# Apply the mapping to the 'region' column\n",
    "df['region'] = df['region'].map(region_to_continent)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T10:57:21.262308Z",
     "start_time": "2024-01-10T10:57:21.253624Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique schedules: ['I do multiple workouts in a day 2x a week|' nan\n",
      " 'I usually only do 1 workout a day|'\n",
      " 'I usually only do 1 workout a day|I strictly schedule my rest days|'\n",
      " 'I usually only do 1 workout a day|I typically rest 4 or more days per month|'\n",
      " 'I do multiple workouts in a day 3+ times a week|I typically rest fewer than 4 days per month|'\n",
      " 'I do multiple workouts in a day 3+ times a week|'\n",
      " 'I usually only do 1 workout a day|I do multiple workouts in a day 1x a week|I typically rest 4 or more days per month|'\n",
      " 'I do multiple workouts in a day 1x a week|I typically rest 4 or more days per month|'\n",
      " 'I do multiple workouts in a day 1x a week|'\n",
      " 'I typically rest 4 or more days per month|'\n",
      " 'I do multiple workouts in a day 3+ times a week|I strictly schedule my rest days|I typically rest 4 or more days per month|'\n",
      " 'I strictly schedule my rest days|'\n",
      " 'I do multiple workouts in a day 2x a week|I strictly schedule my rest days|I typically rest 4 or more days per month|'\n",
      " 'I do multiple workouts in a day 3+ times a week|I typically rest 4 or more days per month|'\n",
      " 'I usually only do 1 workout a day|I do multiple workouts in a day 3+ times a week|I typically rest 4 or more days per month|'\n",
      " 'I do multiple workouts in a day 2x a week|I typically rest 4 or more days per month|'\n",
      " 'I do multiple workouts in a day 1x a week|I typically rest fewer than 4 days per month|'\n",
      " 'I do multiple workouts in a day 1x a week|I strictly schedule my rest days|I typically rest 4 or more days per month|'\n",
      " 'I usually only do 1 workout a day|I typically rest fewer than 4 days per month|'\n",
      " 'I usually only do 1 workout a day|I do multiple workouts in a day 2x a week|I typically rest 4 or more days per month|'\n",
      " 'I do multiple workouts in a day 3+ times a week|I strictly schedule my rest days|I typically rest fewer than 4 days per month|'\n",
      " 'I do multiple workouts in a day 2x a week|I strictly schedule my rest days|'\n",
      " 'I do multiple workouts in a day 3+ times a week|I strictly schedule my rest days|'\n",
      " 'I typically rest fewer than 4 days per month|' 'Decline to answer|'\n",
      " 'I usually only do 1 workout a day|I do multiple workouts in a day 2x a week|I strictly schedule my rest days|'\n",
      " 'I usually only do 1 workout a day|I do multiple workouts in a day 1x a week|'\n",
      " 'I usually only do 1 workout a day|I do multiple workouts in a day 2x a week|'\n",
      " 'I usually only do 1 workout a day|I do multiple workouts in a day 1x a week|I strictly schedule my rest days|I typically rest 4 or more days per month|'\n",
      " 'I do multiple workouts in a day 2x a week|I typically rest fewer than 4 days per month|'\n",
      " 'I usually only do 1 workout a day|I do multiple workouts in a day 1x a week|I typically rest fewer than 4 days per month|'\n",
      " 'I usually only do 1 workout a day|I strictly schedule my rest days|I typically rest 4 or more days per month|'\n",
      " 'I usually only do 1 workout a day|I do multiple workouts in a day 3+ times a week|'\n",
      " 'I usually only do 1 workout a day|I do multiple workouts in a day 2x a week|I typically rest fewer than 4 days per month|'\n",
      " 'I usually only do 1 workout a day|I do multiple workouts in a day 1x a week|I strictly schedule my rest days|'\n",
      " 'I do multiple workouts in a day 1x a week|I strictly schedule my rest days|'\n",
      " 'I usually only do 1 workout a day|I do multiple workouts in a day 2x a week|I strictly schedule my rest days|I typically rest 4 or more days per month|'\n",
      " 'I usually only do 1 workout a day|I strictly schedule my rest days|I typically rest fewer than 4 days per month|'\n",
      " 'I strictly schedule my rest days|I typically rest 4 or more days per month|'\n",
      " 'I do multiple workouts in a day 2x a week|I strictly schedule my rest days|I typically rest fewer than 4 days per month|']\n"
     ]
    }
   ],
   "source": [
    "#Data exploration to map the schedules in a meaningful way\n",
    "unique_schedules = df['schedule'].unique()\n",
    "print(\"Unique schedules:\", unique_schedules)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T10:57:21.275413Z",
     "start_time": "2024-01-10T10:57:21.268056Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "outputs": [],
   "source": [
    "#mapping of the schedules to meaningful strings\n",
    "schedule_generalization = {\n",
    "    'I usually only do 1 workout a day|': 'Single Daily Workout',\n",
    "    'I do multiple workouts in a day 1x a week|': 'Multiple Weekly Workouts',\n",
    "    'I do multiple workouts in a day 2x a week|': 'Multiple Weekly Workouts',\n",
    "    'I do multiple workouts in a day 3+ times a week|': 'Frequent Workouts',\n",
    "    'I typically rest 4 or more days per month|': 'Regular Rest Days',\n",
    "    'I typically rest fewer than 4 days per month|': 'Fewer Rest Days',\n",
    "    'I strictly schedule my rest days|': 'Strictly Scheduled Rest',\n",
    "    'Decline to answer|': 'Other/Declined to Answer',\n",
    "    'I usually only do 1 workout a day|I strictly schedule my rest days|': 'Strictly Scheduled Rest',\n",
    "    'I usually only do 1 workout a day|I typically rest 4 or more days per month|': 'Regular Rest Days',\n",
    "    'I do multiple workouts in a day 3+ times a week|I typically rest fewer than 4 days per month|': 'Frequent Workouts',\n",
    "    'I usually only do 1 workout a day|I do multiple workouts in a day 1x a week|I typically rest 4 or more days per month|': 'Multiple Weekly Workouts',\n",
    "    'I do multiple workouts in a day 1x a week|I typically rest 4 or more days per month|': 'Regular Rest Days',\n",
    "    'I do multiple workouts in a day 3+ times a week|I strictly schedule my rest days|I typically rest 4 or more days per month|': 'Strictly Scheduled Rest',\n",
    "    'I do multiple workouts in a day 2x a week|I strictly schedule my rest days|I typically rest 4 or more days per month|': 'Strictly Scheduled Rest',\n",
    "    'I do multiple workouts in a day 3+ times a week|I typically rest 4 or more days per month|': 'Regular Rest Days',\n",
    "    'I usually only do 1 workout a day|I do multiple workouts in a day 3+ times a week|I typically rest 4 or more days per month|': 'Multiple Weekly Workouts',\n",
    "    'I do multiple workouts in a day 2x a week|I typically rest 4 or more days per month|': 'Regular Rest Days',\n",
    "    'I do multiple workouts in a day 1x a week|I typically rest fewer than 4 days per month|': 'Fewer Rest Days',\n",
    "    'I do multiple workouts in a day 1x a week|I strictly schedule my rest days|I typically rest 4 or more days per month|': 'Strictly Scheduled Rest',\n",
    "    'I usually only do 1 workout a day|I typically rest fewer than 4 days per month|': 'Fewer Rest Days',\n",
    "    'I usually only do 1 workout a day|I do multiple workouts in a day 2x a week|I typically rest 4 or more days per month|': 'Multiple Weekly Workouts',\n",
    "    'I usually only do 1 workout a day|I do multiple workouts in a day 1x a week|I strictly schedule my rest days|': 'Mixed Workout Frequency',\n",
    "    'I do multiple workouts in a day 1x a week|I strictly schedule my rest days|': 'Scheduled Multiple Workouts',\n",
    "    'I usually only do 1 workout a day|I do multiple workouts in a day 2x a week|I strictly schedule my rest days|I typically rest 4 or more days per month|': 'Regular Workout with Strict Rest Days',\n",
    "    'I usually only do 1 workout a day|I strictly schedule my rest days|I typically rest fewer than 4 days per month|': 'Regular Rest with Strict Scheduling',\n",
    "    'I strictly schedule my rest days|I typically rest 4 or more days per month|': 'Regular Rest with Strict Scheduling',\n",
    "    'I do multiple workouts in a day 2x a week|I strictly schedule my rest days|I typically rest fewer than 4 days per month|': 'Frequent Workouts with Strict Rest Days',\n",
    "    'NA': 'NA'\n",
    "}\n",
    "\n",
    "# Apply the generalization to the 'schedule' column\n",
    "df['schedule'] = df['schedule'].map(schedule_generalization)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T10:57:21.294433Z",
     "start_time": "2024-01-10T10:57:21.270251Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique eat attributes: [nan 'I eat 1-3 full cheat meals per week|'\n",
      " \"I eat quality foods but don't measure the amount|\" 'I eat strict Paleo|'\n",
      " \"I eat quality foods but don't measure the amount|I eat 1-3 full cheat meals per week|\"\n",
      " 'I eat whatever is convenient|'\n",
      " \"I eat strict Paleo|I eat quality foods but don't measure the amount|\"\n",
      " 'I eat strict Paleo|I eat 1-3 full cheat meals per week|'\n",
      " \"I eat quality foods but don't measure the amount|I eat whatever is convenient|I eat 1-3 full cheat meals per week|\"\n",
      " \"I eat quality foods but don't measure the amount|I eat whatever is convenient|\"\n",
      " 'I eat whatever is convenient|I eat 1-3 full cheat meals per week|'\n",
      " 'Decline to answer|' 'I weigh and measure my food|'\n",
      " 'I weigh and measure my food|I eat strict Paleo|I eat 1-3 full cheat meals per week|'\n",
      " \"I eat strict Paleo|I eat quality foods but don't measure the amount|I eat 1-3 full cheat meals per week|\"\n",
      " 'I weigh and measure my food|I eat strict Paleo|'\n",
      " \"I weigh and measure my food|I eat quality foods but don't measure the amount|I eat 1-3 full cheat meals per week|\"\n",
      " 'I weigh and measure my food|I eat 1-3 full cheat meals per week|'\n",
      " \"I weigh and measure my food|I eat quality foods but don't measure the amount|\"\n",
      " 'I weigh and measure my food|I eat whatever is convenient|']\n"
     ]
    }
   ],
   "source": [
    "#Data exploration to map the eat attribute in a meaningful way\n",
    "unique_eat = df['eat'].unique()\n",
    "print(\"Unique eat attributes:\", unique_eat)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T10:57:21.295686Z",
     "start_time": "2024-01-10T10:57:21.293953Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "outputs": [],
   "source": [
    "# Mapping of eating habits to meaningful strings\n",
    "eat_generalization = {\n",
    "    'I eat 1-3 full cheat meals per week|': 'Cheat Meals/Other',\n",
    "    \"I eat quality foods but don't measure the amount|\": 'Quality Focused',\n",
    "    'I eat strict Paleo|': 'Diet-Conscious',\n",
    "    \"I eat quality foods but don't measure the amount|I eat 1-3 full cheat meals per week|\": 'Quality Focused',\n",
    "    'I eat whatever is convenient|': 'Convenience Eating',\n",
    "    \"I eat strict Paleo|I eat quality foods but don't measure the amount|\": 'Diet-Conscious',\n",
    "    'I eat strict Paleo|I eat 1-3 full cheat meals per week|': 'Diet-Conscious',\n",
    "    \"I eat quality foods but don't measure the amount|I eat whatever is convenient|I eat 1-3 full cheat meals per week|\": 'Quality Focused',\n",
    "    \"I eat quality foods but don't measure the amount|I eat whatever is convenient|\": 'Quality Focused',\n",
    "    'I eat whatever is convenient|I eat 1-3 full cheat meals per week|': 'Convenience Eating',\n",
    "    'Decline to answer|': 'Cheat Meals/Other',\n",
    "    'I weigh and measure my food|': 'Diet-Conscious',\n",
    "    'I weigh and measure my food|I eat strict Paleo|I eat 1-3 full cheat meals per week|': 'Diet-Conscious',\n",
    "    \"I eat strict Paleo|I eat quality foods but don't measure the amount|I eat 1-3 full cheat meals per week|\": 'Diet-Conscious',\n",
    "    'I weigh and measure my food|I eat strict Paleo|': 'Diet-Conscious',\n",
    "    \"I weigh and measure my food|I eat quality foods but don't measure the amount|I eat 1-3 full cheat meals per week|\": 'Diet-Conscious',\n",
    "    'I weigh and measure my food|I eat 1-3 full cheat meals per week|': 'Diet-Conscious',\n",
    "    \"I weigh and measure my food|I eat quality foods but don't measure the amount|\": 'Diet-Conscious',\n",
    "    'I weigh and measure my food|I eat whatever is convenient|': 'Diet-Conscious',\n",
    "    'NA': 'NA'\n",
    "}\n",
    "\n",
    "# Apply the generalization to the 'eat' column\n",
    "df['eat'] = df['eat'].map(eat_generalization)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T10:57:21.313164Z",
     "start_time": "2024-01-10T10:57:21.305101Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique howlong attributes: ['4+ years|' nan '1-2 years|' '2-4 years|' '6-12 months|'\n",
      " 'Less than 6 months|' '1-2 years|2-4 years|'\n",
      " 'Less than 6 months|1-2 years|' '2-4 years|4+ years|'\n",
      " 'Decline to answer|' '6-12 months|1-2 years|']\n"
     ]
    }
   ],
   "source": [
    "#Data exploration to map the howlong attribute in a meaningful way\n",
    "unique_howlong = df['howlong'].unique()\n",
    "print(\"Unique howlong attributes:\", unique_howlong)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T10:57:21.331911Z",
     "start_time": "2024-01-10T10:57:21.318542Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "outputs": [],
   "source": [
    "# mapping for the 'howlong' attribute\n",
    "howlong_generalization = {\n",
    "    '4+ years|': 'Experienced',\n",
    "    '1-2 years|': 'Experienced',\n",
    "    '2-4 years|': 'Experienced',\n",
    "    '6-12 months|': 'Novice',\n",
    "    'Less than 6 months|': 'Novice',\n",
    "    '1-2 years|2-4 years|': 'Experienced',\n",
    "    'Less than 6 months|1-2 years|': 'Novice',\n",
    "    '2-4 years|4+ years|': 'Experienced',\n",
    "    'Decline to answer|': 'NA',\n",
    "    '6-12 months|1-2 years|': 'Novice',\n",
    "    'NA': 'NA'\n",
    "}\n",
    "\n",
    "# Map the 'howlong' values to the categories\n",
    "df['howlong'] = df['howlong'].map(howlong_generalization)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T10:57:21.344301Z",
     "start_time": "2024-01-10T10:57:21.330284Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 5. Ensure that there are at least k records for each combination of quasi-identifiers\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 420955\n",
      "Unique values in each column:\n",
      " region       6\n",
      "gender       2\n",
      "age          4\n",
      "height       4\n",
      "weight       6\n",
      "eat          4\n",
      "schedule    12\n",
      "howlong      3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Check how many unique values there are in each column\n",
    "num_rows = len(df)\n",
    "print(\"Number of rows:\", num_rows)\n",
    "\n",
    "columns_of_interest = ['region', 'gender', 'age', 'height', 'weight', 'eat', 'schedule', 'howlong']\n",
    "selected_df = df[columns_of_interest]\n",
    "\n",
    "unique_values = selected_df.nunique()\n",
    "print(\"Unique values in each column:\\n\", unique_values)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T10:57:21.397548Z",
     "start_time": "2024-01-10T10:57:21.338370Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset does NOT satisfy k=2 anonymity.\n",
      "Groups that occur only once:\n",
      "              region  gender    age height   weight                eat  \\\n",
      "0            Africa  Female   0-18  60-70    0-159     Diet-Conscious   \n",
      "1            Africa  Female   0-18  60-70    0-159    Quality Focused   \n",
      "2            Africa  Female  19-30  40-60    0-159    Quality Focused   \n",
      "3            Africa  Female  19-30  60-70    0-159  Cheat Meals/Other   \n",
      "4            Africa  Female  19-30  60-70    0-159  Cheat Meals/Other   \n",
      "...             ...     ...    ...    ...      ...                ...   \n",
      "6499  South America    Male  46-60  70-80  170-179    Quality Focused   \n",
      "6500  South America    Male  46-60  70-80  180-189     Diet-Conscious   \n",
      "6501  South America    Male  46-60  70-80  190-199     Diet-Conscious   \n",
      "6502  South America    Male  46-60  70-80  190-199    Quality Focused   \n",
      "6503  South America    Male  46-60  70-80     200+    Quality Focused   \n",
      "\n",
      "                  schedule      howlong  count  \n",
      "0     Single Daily Workout  Experienced      1  \n",
      "1        Frequent Workouts  Experienced      1  \n",
      "2     Single Daily Workout       Novice      1  \n",
      "3        Frequent Workouts       Novice      1  \n",
      "4     Single Daily Workout  Experienced      1  \n",
      "...                    ...          ...    ...  \n",
      "6499  Single Daily Workout  Experienced      1  \n",
      "6500     Regular Rest Days  Experienced      1  \n",
      "6501  Single Daily Workout  Experienced      1  \n",
      "6502     Regular Rest Days  Experienced      1  \n",
      "6503     Frequent Workouts       Novice      1  \n",
      "\n",
      "[3163 rows x 9 columns]\n",
      "Number of groups not satisfying k=2 anonymity: 3163\n"
     ]
    }
   ],
   "source": [
    "# Group by quasi-identifiers\n",
    "grouped_df = df.groupby(['region', 'gender', 'age', 'height', 'weight', 'eat', 'schedule', 'howlong'], observed=True).size().reset_index(name='count')\n",
    "\n",
    "# Check the minimum count\n",
    "min_count = grouped_df['count'].min()\n",
    "non_compliant_groups = grouped_df[grouped_df['count'] < 2]\n",
    "# Verify if k-anonymity is achieved\n",
    "if min_count >= 2:\n",
    "    print(\"The dataset satisfies k=2 anonymity.\")\n",
    "    \n",
    "else:\n",
    "    print(\"The dataset does NOT satisfy k=2 anonymity.\")\n",
    "\n",
    "    # Display groups that occur only once\n",
    "    only_once = grouped_df[grouped_df['count'] == 1]\n",
    "    print(\"Groups that occur only once:\\n\", only_once)\n",
    "    \n",
    "    num_non_compliant = len(non_compliant_groups)\n",
    "    print(\"Number of groups not satisfying k=2 anonymity:\", num_non_compliant)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T10:57:21.476125Z",
     "start_time": "2024-01-10T10:57:21.397220Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
