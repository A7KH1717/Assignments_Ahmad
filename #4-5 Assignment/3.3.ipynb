{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 3.3 Experiments â€“ 20 marks"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6bebe18acebe4abd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.3.1 Design experiments to test the following: The utility of the data that you have generated using your proposed anonymisation scheme (algorithms) for Q2.c.\n",
    "\n",
    "First, we start with preprocessing measures to ensure we can compare the utility of our data accordingly. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f698bef49c8555a"
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    manner_of_death       armed gender race state  signs_of_mental_illness  \\\n",
      "0              shot         gun      M    A    WA                     True   \n",
      "1              shot         gun      M    W    OR                    False   \n",
      "2  shot and Tasered     unarmed      M    H    KS                    False   \n",
      "3              shot  toy weapon      M    W    CA                     True   \n",
      "4              shot    nail gun      M    H    CO                    False   \n",
      "\n",
      "  threat_level         flee  body_camera    year   age  \n",
      "0       attack  Not fleeing        False  2016.5  45.5  \n",
      "1       attack  Not fleeing        False  2016.5  45.5  \n",
      "2        other  Not fleeing        False  2016.5  15.0  \n",
      "3       attack  Not fleeing        False  2016.5  45.5  \n",
      "4       attack  Not fleeing        False  2016.5  45.5  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "def interval_to_middle(value):\n",
    "    if pd.isna(value):\n",
    "        return np.nan  \n",
    "    start, end = value.split('-')\n",
    "    start = int(start)\n",
    "    end = int(end)\n",
    "    # Calculate the middle value of the interval\n",
    "    middle = (start + end) / 2\n",
    "    return middle\n",
    "\n",
    "# Apply preprocessing measures to be able to compare our two datasets\n",
    "orig_df = pd.read_csv(\"police-shooting.csv\")\n",
    "orig_df = orig_df.drop(['city', 'name', 'longitude', 'latitude', 'is_geocoding_exact', 'id'], axis=1)\n",
    "\n",
    "orig_df['year'] = pd.to_datetime(orig_df['date']).dt.year\n",
    "orig_df = orig_df.drop(['date'], axis=1)\n",
    "\n",
    "anon_df = pd.read_csv(\"k_anon_police.csv\")\n",
    "anon_df['year'] = anon_df['year_range'].apply(interval_to_middle)\n",
    "anon_df['age'] = anon_df['age_range'].apply(interval_to_middle)\n",
    "anon_df = anon_df.drop(['year_range', 'age_range', 'id'], axis=1)\n",
    "\n",
    "print(anon_df.iloc[:5])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T18:43:25.469096Z",
     "start_time": "2024-03-05T18:43:25.399480Z"
    }
   },
   "id": "b8724c5f92389f5e"
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    manner_of_death       armed   age gender race state  \\\n",
      "0              shot         gun  53.0      M    A    WA   \n",
      "1              shot         gun  47.0      M    W    OR   \n",
      "2  shot and Tasered     unarmed  23.0      M    H    KS   \n",
      "3              shot  toy weapon  32.0      M    W    CA   \n",
      "4              shot    nail gun  39.0      M    H    CO   \n",
      "\n",
      "   signs_of_mental_illness threat_level         flee  body_camera  year  \n",
      "0                     True       attack  Not fleeing        False  2015  \n",
      "1                    False       attack  Not fleeing        False  2015  \n",
      "2                    False        other  Not fleeing        False  2015  \n",
      "3                     True       attack  Not fleeing        False  2015  \n",
      "4                    False       attack  Not fleeing        False  2015  \n"
     ]
    }
   ],
   "source": [
    "print(orig_df.iloc[:5])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T18:43:25.470272Z",
     "start_time": "2024-03-05T18:43:25.453652Z"
    }
   },
   "id": "536f094700215d0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "When preprocessing is done, we compare the cardinality of each of the attributes."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "298a10d2aae6a101"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Attribute  Original Cardinality  Anonymized Cardinality\n",
      "        manner_of_death              0.000250                0.000250\n",
      "                  armed              0.013628                0.013628\n",
      "                    age              0.010816                0.000401\n",
      "                 gender              0.000251                0.000251\n",
      "                   race              0.000927                0.000927\n",
      "                  state              0.006384                0.006384\n",
      "signs_of_mental_illness              0.000250                0.000250\n",
      "           threat_level              0.000376                0.000376\n",
      "                   flee              0.000569                0.000569\n",
      "            body_camera              0.000250                0.000250\n",
      "                   year              0.001001                0.000376\n"
     ]
    }
   ],
   "source": [
    "cardinalities_orig = {}\n",
    "cardinalities_anon = {}\n",
    "\n",
    "for column in orig_df.columns:\n",
    "    u = orig_df[column].nunique() \n",
    "    n = orig_df[column].count()  \n",
    "    c = u / n  # Cardinality calculation\n",
    "    cardinalities_orig[column] = c\n",
    "    \n",
    "for column in anon_df.columns:\n",
    "    u = anon_df[column].nunique() \n",
    "    n = anon_df[column].count()  \n",
    "    c = u / n  # Cardinality calculation\n",
    "    cardinalities_anon[column] = c\n",
    "\n",
    "    \n",
    "df_orig_cardinalities = pd.DataFrame(list(cardinalities_orig.items()), columns=['Attribute', 'Original Cardinality'])\n",
    "df_anon_cardinalities = pd.DataFrame(list(cardinalities_anon.items()), columns=['Attribute', 'Anonymized Cardinality'])\n",
    "combined_cardinalities = pd.merge(df_orig_cardinalities, df_anon_cardinalities, on='Attribute')\n",
    "print(combined_cardinalities.to_string(index=False))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T18:43:25.510434Z",
     "start_time": "2024-03-05T18:43:25.472457Z"
    }
   },
   "id": "ed04505e8b7a9d12",
   "execution_count": 331
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then, we proceed by displaying the minimum value, mean value, 25th percentile value, 75th percentile value, standard derivation and the total value count for the numerical values in both of the datasets."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c83525f8c784a065"
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "outputs": [
    {
     "data": {
      "text/plain": "      orig_count    orig_mean   orig_std  orig_min  orig_25%  orig_50%  \\\nage       7489.0    37.215917  12.986545       2.0      27.0      35.0   \nyear      7989.0  2018.536863   2.290178    2015.0    2017.0    2019.0   \n\n      orig_75%  orig_max  anon_count    anon_mean   anon_std  anon_min  \\\nage       45.0      92.0      7489.0    38.072573  17.868025      15.0   \nyear    2021.0    2022.0      7989.0  2019.483352   2.556590    2016.5   \n\n      anon_25%  anon_50%  anon_75%  anon_max  \nage       15.0      45.5      45.5      80.5  \nyear    2016.5    2020.0    2023.0    2023.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>orig_count</th>\n      <th>orig_mean</th>\n      <th>orig_std</th>\n      <th>orig_min</th>\n      <th>orig_25%</th>\n      <th>orig_50%</th>\n      <th>orig_75%</th>\n      <th>orig_max</th>\n      <th>anon_count</th>\n      <th>anon_mean</th>\n      <th>anon_std</th>\n      <th>anon_min</th>\n      <th>anon_25%</th>\n      <th>anon_50%</th>\n      <th>anon_75%</th>\n      <th>anon_max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>age</th>\n      <td>7489.0</td>\n      <td>37.215917</td>\n      <td>12.986545</td>\n      <td>2.0</td>\n      <td>27.0</td>\n      <td>35.0</td>\n      <td>45.0</td>\n      <td>92.0</td>\n      <td>7489.0</td>\n      <td>38.072573</td>\n      <td>17.868025</td>\n      <td>15.0</td>\n      <td>15.0</td>\n      <td>45.5</td>\n      <td>45.5</td>\n      <td>80.5</td>\n    </tr>\n    <tr>\n      <th>year</th>\n      <td>7989.0</td>\n      <td>2018.536863</td>\n      <td>2.290178</td>\n      <td>2015.0</td>\n      <td>2017.0</td>\n      <td>2019.0</td>\n      <td>2021.0</td>\n      <td>2022.0</td>\n      <td>7989.0</td>\n      <td>2019.483352</td>\n      <td>2.556590</td>\n      <td>2016.5</td>\n      <td>2016.5</td>\n      <td>2020.0</td>\n      <td>2023.0</td>\n      <td>2023.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_original = orig_df.describe().transpose()\n",
    "stats_anonymized = anon_df.describe().transpose()\n",
    "\n",
    "stats_original.columns = ['orig_' + col for col in stats_original.columns]\n",
    "stats_anonymized.columns = ['anon_' + col for col in stats_anonymized.columns]\n",
    "\n",
    "combined_stats = pd.merge(stats_original, stats_anonymized, left_index=True, right_index=True)\n",
    "\n",
    "combined_stats"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T18:43:25.525673Z",
     "start_time": "2024-03-05T18:43:25.507904Z"
    }
   },
   "id": "b575f803e1118df5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now progress in comparing if there is a difference in the number of missing values in the two datasets. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "acf228b20a574c9e"
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "outputs": [
    {
     "data": {
      "text/plain": "                         original_missing_perc  anonymized_missing_percentage\nage                                   6.258606                       6.258606\narmed                                 2.641132                       2.641132\nbody_camera                           0.000000                       0.000000\nflee                                 11.978971                      11.978971\ngender                                0.388034                       0.388034\nmanner_of_death                       0.000000                       0.000000\nrace                                 18.976092                      18.976092\nsigns_of_mental_illness               0.000000                       0.000000\nstate                                 0.000000                       0.000000\nthreat_level                          0.000000                       0.000000\nyear                                  0.000000                       0.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>original_missing_perc</th>\n      <th>anonymized_missing_percentage</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>age</th>\n      <td>6.258606</td>\n      <td>6.258606</td>\n    </tr>\n    <tr>\n      <th>armed</th>\n      <td>2.641132</td>\n      <td>2.641132</td>\n    </tr>\n    <tr>\n      <th>body_camera</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>flee</th>\n      <td>11.978971</td>\n      <td>11.978971</td>\n    </tr>\n    <tr>\n      <th>gender</th>\n      <td>0.388034</td>\n      <td>0.388034</td>\n    </tr>\n    <tr>\n      <th>manner_of_death</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>race</th>\n      <td>18.976092</td>\n      <td>18.976092</td>\n    </tr>\n    <tr>\n      <th>signs_of_mental_illness</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>state</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>threat_level</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>year</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_original = orig_df.isnull().sum()\n",
    "missing_anonymized = anon_df.isnull().sum()\n",
    "\n",
    "original_missing_percentage = (missing_original / len(orig_df)) * 100\n",
    "anonymized_missing_percentage = (missing_anonymized / len(anon_df)) * 100\n",
    "\n",
    "completeness_comparison = pd.DataFrame({\n",
    "    'original_missing_perc': original_missing_percentage,\n",
    "    'anonymized_missing_percentage': anonymized_missing_percentage\n",
    "})\n",
    "\n",
    "completeness_comparison"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T18:43:25.539145Z",
     "start_time": "2024-03-05T18:43:25.532159Z"
    }
   },
   "id": "cdd144c88173fc9e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now proceed with calculating the pearson coefficient in numerical attributes of our two datasets. The Pearson correlation coefficient measures the linear correlation between two sets of data, ranging from -1 to 1. A coefficient of 1 indicates a perfect positive linear relationship, -1 indicates a perfect negative linear relationship, and 0 indicates no linear relationship."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a43b45eb33630bd"
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "outputs": [
    {
     "data": {
      "text/plain": "{'age': 0.8408002425947383, 'year': 0.9447358199395686}"
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "# Initialize an empty dictionary to store the correlations\n",
    "correlations = {}\n",
    "\n",
    "# Iterate through each column in the original DataFrame\n",
    "for column in orig_df.columns:\n",
    "    # Check if the column exists in the anonymized DataFrame and is numeric\n",
    "    if column in anon_df.columns and orig_df[column].dtype in [np.float64, np.int64, np.int32]:\n",
    "        # Combine the current column's data from both DataFrames and drop missing values\n",
    "        combined = pd.concat([orig_df[column], anon_df[column]], axis=1, keys=['original', 'anonymized']).dropna()\n",
    "        # Calculate the Pearson correlation coefficient for the combined data\n",
    "        correlation = pearsonr(combined['original'], combined['anonymized'])[0]\n",
    "        # Store the correlation coefficient in the dictionary\n",
    "        correlations[column] = correlation\n",
    "\n",
    "correlations"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T18:43:25.554427Z",
     "start_time": "2024-03-05T18:43:25.536484Z"
    }
   },
   "id": "e04feae7401ab7b7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "526464e927aebc52"
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'DataFrame'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/4p/4kctgn5n2378x2bnhkqv4xpc0000gn/T/ipykernel_5567/2385964251.py\u001B[0m in \u001B[0;36m?\u001B[0;34m()\u001B[0m\n\u001B[0;32m---> 15\u001B[0;31m \u001B[0;32mdef\u001B[0m \u001B[0mcorrelation_analysis\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moriginal\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0manonymized\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     16\u001B[0m     \u001B[0mcorrelations\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mcolumn\u001B[0m \u001B[0;32min\u001B[0m \u001B[0moriginal\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     18\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mcolumn\u001B[0m \u001B[0;32min\u001B[0m \u001B[0manonymized\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0moriginal\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mcolumn\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdtype\u001B[0m \u001B[0;32min\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloat64\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mint64\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mint32\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/PPOD/.venv/lib/python3.9/site-packages/pandas/core/frame.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, other, axis, drop, method, numeric_only)\u001B[0m\n\u001B[1;32m  10942\u001B[0m         \u001B[0md\u001B[0m    \u001B[0;36m1.0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m  10943\u001B[0m         \u001B[0me\u001B[0m    \u001B[0mNaN\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m  10944\u001B[0m         \u001B[0mdtype\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mfloat64\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m  10945\u001B[0m         \"\"\"  # noqa: E501\n\u001B[0;32m> 10946\u001B[0;31m         \u001B[0maxis\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_axis_number\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0maxis\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m  10947\u001B[0m         \u001B[0mthis\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_numeric_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mnumeric_only\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m  10948\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m  10949\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mother\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mSeries\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/PPOD/.venv/lib/python3.9/site-packages/pandas/core/generic.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(cls, axis)\u001B[0m\n\u001B[1;32m    550\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_get_axis_number\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcls\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mAxis\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mAxisInt\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    551\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    552\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mcls\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_AXIS_TO_AXIS_NUMBER\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0maxis\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    553\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 554\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"No axis named {axis} for object type {cls.__name__}\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m: unhashable type: 'DataFrame'"
     ]
    }
   ],
   "source": [
    "def correlation_analysis(original, anonymized):\n",
    "    correlations = {}\n",
    "    for column in original.columns:\n",
    "        if column in anonymized.columns and original[column].dtype in [np.float64, np.int64, np.int32]:\n",
    "            combined = pd.concat([original[column], anonymized[column]], axis=1, keys=['original', 'anonymized']).dropna()\n",
    "            correlation = pearsonr(combined['original'], combined['anonymized'])[0]\n",
    "            correlations[column] = correlation\n",
    "    return correlations\n",
    "\n",
    "# Initialize dictionaries to store results\n",
    "similarity_results = {}\n",
    "mae_results = {}\n",
    "rmse_results = {}\n",
    "\n",
    "correlations = orig_df.corrwith(orig_df, anon_df)\n",
    "similarity_results['pearson_correlation'] = correlations\n",
    "\n",
    "# Loop through columns to calculate MAE and RMSE for numeric columns\n",
    "for column in orig_df.columns:\n",
    "    print(column)\n",
    "    if column in anon_df.columns and orig_df[column].dtype in [np.float64, np.int64, np.int32]:\n",
    "        print(column)\n",
    "        original_col_data = orig_df[column].dropna()\n",
    "        anonymized_col_data = anon_df.loc[original_col_data.index, column]\n",
    "        mae = np.mean(np.abs(original_col_data - anonymized_col_data))\n",
    "        rmse = np.sqrt(np.mean((original_col_data - anonymized_col_data) ** 2))\n",
    "        mae_results[column] = mae\n",
    "        rmse_results[column] = rmse\n",
    "\n",
    "# Compile final results\n",
    "final_results = {'MAE': mae_results, 'RMSE': rmse_results}\n",
    "\n",
    "# Output results\n",
    "final_results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T18:43:25.599049Z",
     "start_time": "2024-03-05T18:43:25.557684Z"
    }
   },
   "id": "4d10dc7f0b180ac2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.3.2 Design experiments to test the following: Analyse the new (anonymized) dataset for risks of de-anonymization.\n",
    "We are using the same Algorithm proposed in Task 3.2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36bdaca9a9539e25"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import prince\n",
    "import warnings\n",
    "import altair as alt\n",
    "alt.data_transformers.enable(\"vegafusion\")\n",
    "\n",
    "df = pd.read_csv('k_anon_police.csv')\n",
    "# Ignore specific PerformanceWarnings from pandas\n",
    "warnings.filterwarnings('ignore', category=pd.errors.PerformanceWarning)\n",
    "# Load the dataset\n",
    "\n",
    "mca = prince.MCA(\n",
    "    n_components=3,\n",
    "    n_iter=3,\n",
    "    copy=True,\n",
    "    check_input=True,\n",
    "    engine='sklearn',\n",
    "    random_state=42\n",
    ")\n",
    "# Fit FAMD on the dataset\n",
    "mca = mca.fit(df)\n",
    "\n",
    "df_transformed = mca.transform(df)\n",
    "z_scores = np.abs(stats.zscore(df_transformed))\n",
    "outliers = np.where(z_scores > 3) \n",
    "\n",
    "outlier_rows = df.iloc[outliers[0]]\n",
    "outlier_rows.to_csv('athletes_outliers_MCA.csv', index=False)\n",
    "\n",
    "mca.plot(\n",
    "    df,\n",
    "    x_component=0,\n",
    "    y_component=1,\n",
    "    show_column_markers=True,\n",
    "    show_row_markers=True,\n",
    "    show_column_labels=False,\n",
    "    show_row_labels=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-05T18:43:25.565328Z"
    }
   },
   "id": "179ac1df2603e173",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))  \n",
    "plt.scatter(df_transformed[0], df_transformed[1]) \n",
    "\n",
    "plt.title('FAMD Results')\n",
    "plt.xlabel('Component 1')\n",
    "plt.ylabel('Component 2')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show() "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-05T18:43:25.566450Z"
    }
   },
   "id": "48519a7b25fe0bda"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.3.3 Design experiments to test the following: Propose a method of assessing the risk of disclosure (de-anonymisation) and use this metric to evaluate your anonymised datasets (from Assignments #1, and #2-3), the anonymised dataset received from your colleague, and your version of the anonymised dataset that you obtained in Q2.c.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8264dfdf269ac2dd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
