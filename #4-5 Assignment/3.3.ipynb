{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 3.3 Experiments â€“ 20 marks"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6bebe18acebe4abd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.3.1 Design experiments to test the following: The utility of the data that you have generated using your proposed anonymisation scheme (algorithms) for Q2.c.\n",
    "\n",
    "First, we start with preprocessing measures to ensure we can compare the utility of our data accordingly. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f698bef49c8555a"
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    manner_of_death       armed gender race state  signs_of_mental_illness  \\\n",
      "0              shot         gun      M    A    WA                     True   \n",
      "1              shot         gun      M    W    OR                    False   \n",
      "2  shot and Tasered     unarmed      M    H    KS                    False   \n",
      "3              shot  toy weapon      M    W    CA                     True   \n",
      "4              shot    nail gun      M    H    CO                    False   \n",
      "\n",
      "  threat_level         flee  body_camera    year   age  \n",
      "0       attack  Not fleeing        False  2016.5  45.5  \n",
      "1       attack  Not fleeing        False  2016.5  45.5  \n",
      "2        other  Not fleeing        False  2016.5  15.0  \n",
      "3       attack  Not fleeing        False  2016.5  45.5  \n",
      "4       attack  Not fleeing        False  2016.5  45.5  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "def interval_to_middle(value):\n",
    "    if pd.isna(value):\n",
    "        return np.nan  \n",
    "    start, end = value.split('-')\n",
    "    start = int(start)\n",
    "    end = int(end)\n",
    "    # Calculate the middle value of the interval\n",
    "    middle = (start + end) / 2\n",
    "    return middle\n",
    "\n",
    "# Apply preprocessing measures to be able to compare our two datasets\n",
    "orig_df = pd.read_csv(\"police-shooting.csv\")\n",
    "orig_df = orig_df.drop(['city', 'name', 'longitude', 'latitude', 'is_geocoding_exact', 'id'], axis=1)\n",
    "\n",
    "orig_df['year'] = pd.to_datetime(orig_df['date']).dt.year\n",
    "orig_df = orig_df.drop(['date'], axis=1)\n",
    "\n",
    "anon_df = pd.read_csv(\"k_anon_police.csv\")\n",
    "anon_df['year'] = anon_df['year_range'].apply(interval_to_middle)\n",
    "anon_df['age'] = anon_df['age_range'].apply(interval_to_middle)\n",
    "anon_df = anon_df.drop(['year_range', 'age_range', 'id'], axis=1)\n",
    "\n",
    "print(anon_df.iloc[:5])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T18:39:51.268592Z",
     "start_time": "2024-03-05T18:39:51.218315Z"
    }
   },
   "id": "b8724c5f92389f5e"
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    manner_of_death       armed   age gender race state  \\\n",
      "0              shot         gun  53.0      M    A    WA   \n",
      "1              shot         gun  47.0      M    W    OR   \n",
      "2  shot and Tasered     unarmed  23.0      M    H    KS   \n",
      "3              shot  toy weapon  32.0      M    W    CA   \n",
      "4              shot    nail gun  39.0      M    H    CO   \n",
      "\n",
      "   signs_of_mental_illness threat_level         flee  body_camera  year  \n",
      "0                     True       attack  Not fleeing        False  2015  \n",
      "1                    False       attack  Not fleeing        False  2015  \n",
      "2                    False        other  Not fleeing        False  2015  \n",
      "3                     True       attack  Not fleeing        False  2015  \n",
      "4                    False       attack  Not fleeing        False  2015  \n"
     ]
    }
   ],
   "source": [
    "print(orig_df.iloc[:5])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T18:39:51.275897Z",
     "start_time": "2024-03-05T18:39:51.270189Z"
    }
   },
   "id": "536f094700215d0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "When preprocessing is done, we compare the cardinality of each of the attributes."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "298a10d2aae6a101"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Attribute  Original Cardinality  Anonymized Cardinality\n",
      "        manner_of_death              0.000250                0.000250\n",
      "                  armed              0.013628                0.013628\n",
      "                    age              0.010816                0.000401\n",
      "                 gender              0.000251                0.000251\n",
      "                   race              0.000927                0.000927\n",
      "                  state              0.006384                0.006384\n",
      "signs_of_mental_illness              0.000250                0.000250\n",
      "           threat_level              0.000376                0.000376\n",
      "                   flee              0.000569                0.000569\n",
      "            body_camera              0.000250                0.000250\n",
      "                   year              0.001001                0.000376\n"
     ]
    }
   ],
   "source": [
    "cardinalities_orig = {}\n",
    "cardinalities_anon = {}\n",
    "\n",
    "for column in orig_df.columns:\n",
    "    u = orig_df[column].nunique() \n",
    "    n = orig_df[column].count()  \n",
    "    c = u / n  # Cardinality calculation\n",
    "    cardinalities_orig[column] = c\n",
    "    \n",
    "for column in anon_df.columns:\n",
    "    u = anon_df[column].nunique() \n",
    "    n = anon_df[column].count()  \n",
    "    c = u / n  # Cardinality calculation\n",
    "    cardinalities_anon[column] = c\n",
    "\n",
    "    \n",
    "df_orig_cardinalities = pd.DataFrame(list(cardinalities_orig.items()), columns=['Attribute', 'Original Cardinality'])\n",
    "df_anon_cardinalities = pd.DataFrame(list(cardinalities_anon.items()), columns=['Attribute', 'Anonymized Cardinality'])\n",
    "combined_cardinalities = pd.merge(df_orig_cardinalities, df_anon_cardinalities, on='Attribute')\n",
    "print(combined_cardinalities.to_string(index=False))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T18:39:51.296700Z",
     "start_time": "2024-03-05T18:39:51.275391Z"
    }
   },
   "id": "ed04505e8b7a9d12",
   "execution_count": 303
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then, we proceed by displaying the minimum value, mean value, 25th percentile value, 75th percentile value, standard derivation and the total value count for the numerical values in both of the datasets."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c83525f8c784a065"
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "outputs": [
    {
     "data": {
      "text/plain": "      orig_count    orig_mean   orig_std  orig_min  orig_25%  orig_50%  \\\nage       7489.0    37.215917  12.986545       2.0      27.0      35.0   \nyear      7989.0  2018.536863   2.290178    2015.0    2017.0    2019.0   \n\n      orig_75%  orig_max  anon_count    anon_mean   anon_std  anon_min  \\\nage       45.0      92.0      7489.0    38.072573  17.868025      15.0   \nyear    2021.0    2022.0      7989.0  2019.483352   2.556590    2016.5   \n\n      anon_25%  anon_50%  anon_75%  anon_max  \nage       15.0      45.5      45.5      80.5  \nyear    2016.5    2020.0    2023.0    2023.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>orig_count</th>\n      <th>orig_mean</th>\n      <th>orig_std</th>\n      <th>orig_min</th>\n      <th>orig_25%</th>\n      <th>orig_50%</th>\n      <th>orig_75%</th>\n      <th>orig_max</th>\n      <th>anon_count</th>\n      <th>anon_mean</th>\n      <th>anon_std</th>\n      <th>anon_min</th>\n      <th>anon_25%</th>\n      <th>anon_50%</th>\n      <th>anon_75%</th>\n      <th>anon_max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>age</th>\n      <td>7489.0</td>\n      <td>37.215917</td>\n      <td>12.986545</td>\n      <td>2.0</td>\n      <td>27.0</td>\n      <td>35.0</td>\n      <td>45.0</td>\n      <td>92.0</td>\n      <td>7489.0</td>\n      <td>38.072573</td>\n      <td>17.868025</td>\n      <td>15.0</td>\n      <td>15.0</td>\n      <td>45.5</td>\n      <td>45.5</td>\n      <td>80.5</td>\n    </tr>\n    <tr>\n      <th>year</th>\n      <td>7989.0</td>\n      <td>2018.536863</td>\n      <td>2.290178</td>\n      <td>2015.0</td>\n      <td>2017.0</td>\n      <td>2019.0</td>\n      <td>2021.0</td>\n      <td>2022.0</td>\n      <td>7989.0</td>\n      <td>2019.483352</td>\n      <td>2.556590</td>\n      <td>2016.5</td>\n      <td>2016.5</td>\n      <td>2020.0</td>\n      <td>2023.0</td>\n      <td>2023.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_original = orig_df.describe().transpose()\n",
    "stats_anonymized = anon_df.describe().transpose()\n",
    "\n",
    "stats_original.columns = ['orig_' + col for col in stats_original.columns]\n",
    "stats_anonymized.columns = ['anon_' + col for col in stats_anonymized.columns]\n",
    "\n",
    "combined_stats = pd.merge(stats_original, stats_anonymized, left_index=True, right_index=True)\n",
    "\n",
    "combined_stats"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T18:39:51.305497Z",
     "start_time": "2024-03-05T18:39:51.288614Z"
    }
   },
   "id": "b575f803e1118df5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now progress in comparing if there is a difference in the number of missing values in the two datasets. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "acf228b20a574c9e"
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "outputs": [
    {
     "data": {
      "text/plain": "                         original_missing_perc  anonymized_missing_percentage\nage                                   6.258606                       6.258606\narmed                                 2.641132                       2.641132\nbody_camera                           0.000000                       0.000000\nflee                                 11.978971                      11.978971\ngender                                0.388034                       0.388034\nmanner_of_death                       0.000000                       0.000000\nrace                                 18.976092                      18.976092\nsigns_of_mental_illness               0.000000                       0.000000\nstate                                 0.000000                       0.000000\nthreat_level                          0.000000                       0.000000\nyear                                  0.000000                       0.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>original_missing_perc</th>\n      <th>anonymized_missing_percentage</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>age</th>\n      <td>6.258606</td>\n      <td>6.258606</td>\n    </tr>\n    <tr>\n      <th>armed</th>\n      <td>2.641132</td>\n      <td>2.641132</td>\n    </tr>\n    <tr>\n      <th>body_camera</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>flee</th>\n      <td>11.978971</td>\n      <td>11.978971</td>\n    </tr>\n    <tr>\n      <th>gender</th>\n      <td>0.388034</td>\n      <td>0.388034</td>\n    </tr>\n    <tr>\n      <th>manner_of_death</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>race</th>\n      <td>18.976092</td>\n      <td>18.976092</td>\n    </tr>\n    <tr>\n      <th>signs_of_mental_illness</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>state</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>threat_level</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>year</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_original = orig_df.isnull().sum()\n",
    "missing_anonymized = anon_df.isnull().sum()\n",
    "\n",
    "original_missing_percentage = (missing_original / len(orig_df)) * 100\n",
    "anonymized_missing_percentage = (missing_anonymized / len(anon_df)) * 100\n",
    "\n",
    "completeness_comparison = pd.DataFrame({\n",
    "    'original_missing_perc': original_missing_percentage,\n",
    "    'anonymized_missing_percentage': anonymized_missing_percentage\n",
    "})\n",
    "\n",
    "completeness_comparison"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T18:39:51.327225Z",
     "start_time": "2024-03-05T18:39:51.308266Z"
    }
   },
   "id": "cdd144c88173fc9e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now proceed with calculating the pearson coefficient in numerical attributes of our two datasets. The Pearson correlation coefficient measures the linear correlation between two sets of data, ranging from -1 to 1. A coefficient of 1 indicates a perfect positive linear relationship, -1 indicates a perfect negative linear relationship, and 0 indicates no linear relationship."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a43b45eb33630bd"
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "outputs": [
    {
     "data": {
      "text/plain": "{'age': 0.8408002425947383, 'year': 0.9447358199395686}"
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "# Initialize an empty dictionary to store the correlations\n",
    "correlations = {}\n",
    "\n",
    "# Iterate through each column in the original DataFrame\n",
    "for column in orig_df.columns:\n",
    "    # Check if the column exists in the anonymized DataFrame and is numeric\n",
    "    if column in anon_df.columns and orig_df[column].dtype in [np.float64, np.int64, np.int32]:\n",
    "        # Combine the current column's data from both DataFrames and drop missing values\n",
    "        combined = pd.concat([orig_df[column], anon_df[column]], axis=1, keys=['original', 'anonymized']).dropna()\n",
    "        # Calculate the Pearson correlation coefficient for the combined data\n",
    "        correlation = pearsonr(combined['original'], combined['anonymized'])[0]\n",
    "        # Store the correlation coefficient in the dictionary\n",
    "        correlations[column] = correlation\n",
    "\n",
    "correlations"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T18:39:51.342620Z",
     "start_time": "2024-03-05T18:39:51.316748Z"
    }
   },
   "id": "e04feae7401ab7b7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "526464e927aebc52"
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"int\") to str",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[307], line 20\u001B[0m\n\u001B[1;32m     16\u001B[0m rmse_results \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m# Compute correlations - If correlation_analysis is not defined, you could use pandas' built-in method\u001B[39;00m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# For example, if correlation_analysis calculates Pearson correlation:\u001B[39;00m\n\u001B[0;32m---> 20\u001B[0m correlations \u001B[38;5;241m=\u001B[39m \u001B[43morig_df\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcorrwith\u001B[49m\u001B[43m(\u001B[49m\u001B[43manon_df\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpearson\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     21\u001B[0m similarity_results[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpearson_correlation\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m correlations\n\u001B[1;32m     23\u001B[0m \u001B[38;5;66;03m# Loop through columns to calculate MAE and RMSE for numeric columns\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/PPOD/.venv/lib/python3.9/site-packages/pandas/core/frame.py:10966\u001B[0m, in \u001B[0;36mDataFrame.corrwith\u001B[0;34m(self, other, axis, drop, method, numeric_only)\u001B[0m\n\u001B[1;32m  10963\u001B[0m right \u001B[38;5;241m=\u001B[39m right \u001B[38;5;241m+\u001B[39m left \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m  10965\u001B[0m \u001B[38;5;66;03m# demeaned data\u001B[39;00m\n\u001B[0;32m> 10966\u001B[0m ldem \u001B[38;5;241m=\u001B[39m left \u001B[38;5;241m-\u001B[39m \u001B[43mleft\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmean\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnumeric_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnumeric_only\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m  10967\u001B[0m rdem \u001B[38;5;241m=\u001B[39m right \u001B[38;5;241m-\u001B[39m right\u001B[38;5;241m.\u001B[39mmean(numeric_only\u001B[38;5;241m=\u001B[39mnumeric_only)\n\u001B[1;32m  10969\u001B[0m num \u001B[38;5;241m=\u001B[39m (ldem \u001B[38;5;241m*\u001B[39m rdem)\u001B[38;5;241m.\u001B[39msum()\n",
      "File \u001B[0;32m~/PycharmProjects/PPOD/.venv/lib/python3.9/site-packages/pandas/core/frame.py:11335\u001B[0m, in \u001B[0;36mDataFrame.mean\u001B[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001B[0m\n\u001B[1;32m  11327\u001B[0m \u001B[38;5;129m@doc\u001B[39m(make_doc(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmean\u001B[39m\u001B[38;5;124m\"\u001B[39m, ndim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m))\n\u001B[1;32m  11328\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmean\u001B[39m(\n\u001B[1;32m  11329\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m  11333\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m  11334\u001B[0m ):\n\u001B[0;32m> 11335\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmean\u001B[49m\u001B[43m(\u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskipna\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnumeric_only\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m  11336\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(result, Series):\n\u001B[1;32m  11337\u001B[0m         result \u001B[38;5;241m=\u001B[39m result\u001B[38;5;241m.\u001B[39m__finalize__(\u001B[38;5;28mself\u001B[39m, method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmean\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/PPOD/.venv/lib/python3.9/site-packages/pandas/core/generic.py:11984\u001B[0m, in \u001B[0;36mNDFrame.mean\u001B[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001B[0m\n\u001B[1;32m  11977\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmean\u001B[39m(\n\u001B[1;32m  11978\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m  11979\u001B[0m     axis: Axis \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m  11982\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m  11983\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Series \u001B[38;5;241m|\u001B[39m \u001B[38;5;28mfloat\u001B[39m:\n\u001B[0;32m> 11984\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_stat_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m  11985\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmean\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnanops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnanmean\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskipna\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnumeric_only\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m  11986\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/PPOD/.venv/lib/python3.9/site-packages/pandas/core/generic.py:11941\u001B[0m, in \u001B[0;36mNDFrame._stat_function\u001B[0;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001B[0m\n\u001B[1;32m  11937\u001B[0m nv\u001B[38;5;241m.\u001B[39mvalidate_func(name, (), kwargs)\n\u001B[1;32m  11939\u001B[0m validate_bool_kwarg(skipna, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mskipna\u001B[39m\u001B[38;5;124m\"\u001B[39m, none_allowed\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m> 11941\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_reduce\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m  11942\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskipna\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mskipna\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnumeric_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnumeric_only\u001B[49m\n\u001B[1;32m  11943\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/PPOD/.venv/lib/python3.9/site-packages/pandas/core/frame.py:11204\u001B[0m, in \u001B[0;36mDataFrame._reduce\u001B[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001B[0m\n\u001B[1;32m  11200\u001B[0m     df \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mT\n\u001B[1;32m  11202\u001B[0m \u001B[38;5;66;03m# After possibly _get_data and transposing, we are now in the\u001B[39;00m\n\u001B[1;32m  11203\u001B[0m \u001B[38;5;66;03m#  simple case where we can use BlockManager.reduce\u001B[39;00m\n\u001B[0;32m> 11204\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[43mdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_mgr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreduce\u001B[49m\u001B[43m(\u001B[49m\u001B[43mblk_func\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m  11205\u001B[0m out \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39m_constructor_from_mgr(res, axes\u001B[38;5;241m=\u001B[39mres\u001B[38;5;241m.\u001B[39maxes)\u001B[38;5;241m.\u001B[39miloc[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m  11206\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m out_dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m out\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mboolean\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[0;32m~/PycharmProjects/PPOD/.venv/lib/python3.9/site-packages/pandas/core/internals/managers.py:1459\u001B[0m, in \u001B[0;36mBlockManager.reduce\u001B[0;34m(self, func)\u001B[0m\n\u001B[1;32m   1457\u001B[0m res_blocks: \u001B[38;5;28mlist\u001B[39m[Block] \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m   1458\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m blk \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mblocks:\n\u001B[0;32m-> 1459\u001B[0m     nbs \u001B[38;5;241m=\u001B[39m \u001B[43mblk\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreduce\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1460\u001B[0m     res_blocks\u001B[38;5;241m.\u001B[39mextend(nbs)\n\u001B[1;32m   1462\u001B[0m index \u001B[38;5;241m=\u001B[39m Index([\u001B[38;5;28;01mNone\u001B[39;00m])  \u001B[38;5;66;03m# placeholder\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/PPOD/.venv/lib/python3.9/site-packages/pandas/core/internals/blocks.py:377\u001B[0m, in \u001B[0;36mBlock.reduce\u001B[0;34m(self, func)\u001B[0m\n\u001B[1;32m    371\u001B[0m \u001B[38;5;129m@final\u001B[39m\n\u001B[1;32m    372\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mreduce\u001B[39m(\u001B[38;5;28mself\u001B[39m, func) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mlist\u001B[39m[Block]:\n\u001B[1;32m    373\u001B[0m     \u001B[38;5;66;03m# We will apply the function and reshape the result into a single-row\u001B[39;00m\n\u001B[1;32m    374\u001B[0m     \u001B[38;5;66;03m#  Block with the same mgr_locs; squeezing will be done at a higher level\u001B[39;00m\n\u001B[1;32m    375\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[0;32m--> 377\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalues\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    379\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvalues\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    380\u001B[0m         res_values \u001B[38;5;241m=\u001B[39m result\n",
      "File \u001B[0;32m~/PycharmProjects/PPOD/.venv/lib/python3.9/site-packages/pandas/core/frame.py:11136\u001B[0m, in \u001B[0;36mDataFrame._reduce.<locals>.blk_func\u001B[0;34m(values, axis)\u001B[0m\n\u001B[1;32m  11134\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39marray([result])\n\u001B[1;32m  11135\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m> 11136\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskipna\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mskipna\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/PPOD/.venv/lib/python3.9/site-packages/pandas/core/nanops.py:147\u001B[0m, in \u001B[0;36mbottleneck_switch.__call__.<locals>.f\u001B[0;34m(values, axis, skipna, **kwds)\u001B[0m\n\u001B[1;32m    145\u001B[0m         result \u001B[38;5;241m=\u001B[39m alt(values, axis\u001B[38;5;241m=\u001B[39maxis, skipna\u001B[38;5;241m=\u001B[39mskipna, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[1;32m    146\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 147\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43malt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskipna\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mskipna\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/PycharmProjects/PPOD/.venv/lib/python3.9/site-packages/pandas/core/nanops.py:404\u001B[0m, in \u001B[0;36m_datetimelike_compat.<locals>.new_func\u001B[0;34m(values, axis, skipna, mask, **kwargs)\u001B[0m\n\u001B[1;32m    401\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m datetimelike \u001B[38;5;129;01mand\u001B[39;00m mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    402\u001B[0m     mask \u001B[38;5;241m=\u001B[39m isna(values)\n\u001B[0;32m--> 404\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskipna\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mskipna\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    406\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m datetimelike:\n\u001B[1;32m    407\u001B[0m     result \u001B[38;5;241m=\u001B[39m _wrap_results(result, orig_values\u001B[38;5;241m.\u001B[39mdtype, fill_value\u001B[38;5;241m=\u001B[39miNaT)\n",
      "File \u001B[0;32m~/PycharmProjects/PPOD/.venv/lib/python3.9/site-packages/pandas/core/nanops.py:719\u001B[0m, in \u001B[0;36mnanmean\u001B[0;34m(values, axis, skipna, mask)\u001B[0m\n\u001B[1;32m    716\u001B[0m     dtype_count \u001B[38;5;241m=\u001B[39m dtype\n\u001B[1;32m    718\u001B[0m count \u001B[38;5;241m=\u001B[39m _get_counts(values\u001B[38;5;241m.\u001B[39mshape, mask, axis, dtype\u001B[38;5;241m=\u001B[39mdtype_count)\n\u001B[0;32m--> 719\u001B[0m the_sum \u001B[38;5;241m=\u001B[39m \u001B[43mvalues\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msum\u001B[49m\u001B[43m(\u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype_sum\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    720\u001B[0m the_sum \u001B[38;5;241m=\u001B[39m _ensure_numeric(the_sum)\n\u001B[1;32m    722\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m axis \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(the_sum, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mndim\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n",
      "File \u001B[0;32m~/PycharmProjects/PPOD/.venv/lib/python3.9/site-packages/numpy/core/_methods.py:49\u001B[0m, in \u001B[0;36m_sum\u001B[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001B[0m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_sum\u001B[39m(a, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, out\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, keepdims\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m     48\u001B[0m          initial\u001B[38;5;241m=\u001B[39m_NoValue, where\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m---> 49\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mumr_sum\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeepdims\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minitial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwhere\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mTypeError\u001B[0m: can only concatenate str (not \"int\") to str"
     ]
    }
   ],
   "source": [
    "def correlation_analysis(original, anonymized):\n",
    "    correlations = {}\n",
    "    for column in original.columns:\n",
    "        if column in anonymized.columns and original[column].dtype in [np.float64, np.int64, np.int32]:\n",
    "            combined = pd.concat([original[column], anonymized[column]], axis=1, keys=['original', 'anonymized']).dropna()\n",
    "            correlation = pearsonr(combined['original'], combined['anonymized'])[0]\n",
    "            correlations[column] = correlation\n",
    "    return correlations\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Initialize dictionaries to store results\n",
    "similarity_results = {}\n",
    "mae_results = {}\n",
    "rmse_results = {}\n",
    "\n",
    "# Compute correlations - If correlation_analysis is not defined, you could use pandas' built-in method\n",
    "# For example, if correlation_analysis calculates Pearson correlation:\n",
    "correlations = orig_df.corrwith(anon_df, method='pearson')\n",
    "similarity_results['pearson_correlation'] = correlations\n",
    "\n",
    "# Loop through columns to calculate MAE and RMSE for numeric columns\n",
    "for column in orig_df.columns:\n",
    "    if column in anon_df.columns and orig_df[column].dtype in [np.float64, np.int64, np.int32]:\n",
    "        original_col_data = orig_df[column].dropna()\n",
    "        anonymized_col_data = anon_df.loc[original_col_data.index, column]\n",
    "        mae = np.mean(np.abs(original_col_data - anonymized_col_data))\n",
    "        rmse = np.sqrt(np.mean((original_col_data - anonymized_col_data) ** 2))\n",
    "        mae_results[column] = mae\n",
    "        rmse_results[column] = rmse\n",
    "\n",
    "# Compile final results\n",
    "final_results = {'MAE': mae_results, 'RMSE': rmse_results}\n",
    "\n",
    "# Output results\n",
    "final_results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T18:39:51.428071Z",
     "start_time": "2024-03-05T18:39:51.325860Z"
    }
   },
   "id": "4d10dc7f0b180ac2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.3.2 Design experiments to test the following: Analyse the new (anonymized) dataset for risks of de-anonymization.\n",
    "We are using the same Algorithm proposed in Task 3.2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36bdaca9a9539e25"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import prince\n",
    "import warnings\n",
    "import altair as alt\n",
    "alt.data_transformers.enable(\"vegafusion\")\n",
    "\n",
    "df = pd.read_csv('k_anon_police.csv')\n",
    "# Ignore specific PerformanceWarnings from pandas\n",
    "warnings.filterwarnings('ignore', category=pd.errors.PerformanceWarning)\n",
    "# Load the dataset\n",
    "\n",
    "mca = prince.MCA(\n",
    "    n_components=3,\n",
    "    n_iter=3,\n",
    "    copy=True,\n",
    "    check_input=True,\n",
    "    engine='sklearn',\n",
    "    random_state=42\n",
    ")\n",
    "# Fit FAMD on the dataset\n",
    "mca = mca.fit(df)\n",
    "\n",
    "df_transformed = mca.transform(df)\n",
    "z_scores = np.abs(stats.zscore(df_transformed))\n",
    "outliers = np.where(z_scores > 3) \n",
    "\n",
    "outlier_rows = df.iloc[outliers[0]]\n",
    "outlier_rows.to_csv('athletes_outliers_MCA.csv', index=False)\n",
    "\n",
    "mca.plot(\n",
    "    df,\n",
    "    x_component=0,\n",
    "    y_component=1,\n",
    "    show_column_markers=True,\n",
    "    show_row_markers=True,\n",
    "    show_column_labels=False,\n",
    "    show_row_labels=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-05T18:39:51.427677Z"
    }
   },
   "id": "179ac1df2603e173",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))  \n",
    "plt.scatter(df_transformed[0], df_transformed[1]) \n",
    "\n",
    "plt.title('FAMD Results')\n",
    "plt.xlabel('Component 1')\n",
    "plt.ylabel('Component 2')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show() "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T18:39:51.432378Z",
     "start_time": "2024-03-05T18:39:51.430001Z"
    }
   },
   "id": "48519a7b25fe0bda"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.3.3 Design experiments to test the following: Propose a method of assessing the risk of disclosure (de-anonymisation) and use this metric to evaluate your anonymised datasets (from Assignments #1, and #2-3), the anonymised dataset received from your colleague, and your version of the anonymised dataset that you obtained in Q2.c.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8264dfdf269ac2dd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
