{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Assignment #4-5: Anonymising Textual Data and De-Anonymisation\n",
    "- Dataset:  Tweets Emotions [Daset](https://www.kaggle.com/datasets/pashupatigupta/emotion-detection-from-text?resource=download)\n",
    "- Credits: Dataset was put together by Pashipatu Gupta\n",
    "- ToDo: To run the jupyter notebook the requirements.txt need be installed (`pip install -r requirements.txt`)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f3e766beca369aa4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1 Textual Data Anonymisation – 30 marks"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a7c1a5b1a1bad415"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1.1 Do some research to determine what needs to be anonymised in the data and why.\n",
    "- For a better understanding of the structure of the dataset , we display the attribute values\n",
    "    - What columns does the dataset contain and in what format are the attribute values?\n",
    "        - Therefore, each column and the first value of each column (which is not empty or Null) is printed"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "237a8e23efc1b84d"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     tweet_id   sentiment                                            content\n",
      "0  1956967341       empty  @tiffanylue i know  i was listenin to bad habi...\n",
      "1  1956967666     sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
      "2  1956967696     sadness                Funeral ceremony...gloomy friday...\n",
      "3  1956967789  enthusiasm               wants to hang out with friends SOON!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"tweet_emotions.csv\")\n",
    "print(df.iloc[:4])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T15:08:03.969492Z",
     "start_time": "2024-01-26T15:08:03.896189Z"
    }
   },
   "id": "74a9cb538af3b384"
  },
  {
   "cell_type": "markdown",
   "source": [
    "By inspecting the different columns and the data format, the 'content' attribute has the potential to contain explicit personally identifiable information can be identified:\n",
    "1. User Mentions: \n",
    "    - Any instance of @username should be anonymised because it directly points to an individual's account, which is considered personally identifiable information (PII).\n",
    "2. First Names: \n",
    "    - If any first names are used in a context that can identify an individual, such as tagging in combination with other identifying information, they should be anonymised.\n",
    "3. Locations and Specific References: \n",
    "    - Any mention of specific locations, addresses, landmarks, or establishments that could help in identifying an individual should be anonymised.\n",
    "4. Specific Events with Identifiable Information: \n",
    "    - References to specific events that may lead to the identification of individuals, like parties or gatherings with a list of names, should be anonymised.\n",
    "5. Unique Identifiers: \n",
    "    - Any other unique identifiers, such as specific dates, times, or unique events, that could potentially be linked back to an individual.\n",
    "\n",
    "\n",
    "Apart from that, the 'sentiment' attribute is explored further as we don't know by now, how many unique values there actually are and if they would qualify as PII: "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "190ed3635d49ace1"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total lenth of the dataframe:  40000\n",
      "number of unique values in sentiment:  13\n",
      "counts per unique value in sentiment\n",
      "neutral       8638\n",
      "worry         8459\n",
      "happiness     5209\n",
      "sadness       5165\n",
      "love          3842\n",
      "surprise      2187\n",
      "fun           1776\n",
      "relief        1526\n",
      "hate          1323\n",
      "empty          827\n",
      "enthusiasm     759\n",
      "boredom        179\n",
      "anger          110\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"total lenth of the dataframe: \", len(df))\n",
    "\n",
    "# Calculate the number of unique values and the number of entries per unique value\n",
    "unique_counts = df['sentiment'].nunique()\n",
    "value_counts = df['sentiment'].value_counts()\n",
    "\n",
    "print(\"number of unique values in sentiment: \", unique_counts)\n",
    "print(\"counts per unique value in\", value_counts)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T15:08:03.977209Z",
     "start_time": "2024-01-26T15:08:03.972281Z"
    }
   },
   "id": "7409df0e76827242"
  },
  {
   "cell_type": "markdown",
   "source": [
    "By inspecting the 'sentiment' attribute further, we can say that there are 13 different values in the 'sentiment' column. We also know that there are 40,000 tweets in total in the dataset. Given this information, there is no need to anonymize the 'sentiment' attribute."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "48910199218c1788"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1.2 Using a Natural Language Processing library (e.g. Python’s spaCy), analyse the text to identify elements of personally identifiable information (PII).\n",
    "The goal of anonymization is to remove or obscure such details so that the individuals to whom the data pertains cannot be readily identified. The first step is finding the contents, that might actually contain PII.\n",
    "As the first step, we install 'en_core_web_sm', a pre-trained spaCy model suitable for identifying named entities, which include PII. 'en_core_web_sm' is the English model trained on web text. It has been trained on a diverse range of web text, including blogs, news, comments. We've decided on using 'en_core_web_sm' instead of for example 'en_core_web_trf' due to their balance between performance and resource usage.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9ed5640c245c74b6"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm > /dev/null 2>&1; #install model without outputting in console"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T15:08:06.858179Z",
     "start_time": "2024-01-26T15:08:03.978494Z"
    }
   },
   "id": "2c37a5979e8eebe7"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[47], line 14\u001B[0m\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m pii_entities\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m# Apply the function to each content entry in the dataframe\u001B[39;00m\n\u001B[0;32m---> 14\u001B[0m \u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcontent\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43midentify_pii\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;66;03m#df['PII'] = df['content'].apply(identify_pii)\u001B[39;00m\n\u001B[1;32m     17\u001B[0m df\u001B[38;5;241m.\u001B[39mto_csv(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPII_tweet_emotions.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[0;32m~/PycharmProjects/PPOD/.venv/lib/python3.9/site-packages/pandas/core/series.py:4753\u001B[0m, in \u001B[0;36mSeries.apply\u001B[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001B[0m\n\u001B[1;32m   4625\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply\u001B[39m(\n\u001B[1;32m   4626\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   4627\u001B[0m     func: AggFuncType,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4632\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   4633\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m Series:\n\u001B[1;32m   4634\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   4635\u001B[0m \u001B[38;5;124;03m    Invoke function on values of Series.\u001B[39;00m\n\u001B[1;32m   4636\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4751\u001B[0m \u001B[38;5;124;03m    dtype: float64\u001B[39;00m\n\u001B[1;32m   4752\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 4753\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mSeriesApply\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   4754\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4755\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4756\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconvert_dtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4757\u001B[0m \u001B[43m        \u001B[49m\u001B[43mby_row\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mby_row\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4758\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4759\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4760\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/PPOD/.venv/lib/python3.9/site-packages/pandas/core/apply.py:1207\u001B[0m, in \u001B[0;36mSeriesApply.apply\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1204\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_compat()\n\u001B[1;32m   1206\u001B[0m \u001B[38;5;66;03m# self.func is Callable\u001B[39;00m\n\u001B[0;32m-> 1207\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/PPOD/.venv/lib/python3.9/site-packages/pandas/core/apply.py:1287\u001B[0m, in \u001B[0;36mSeriesApply.apply_standard\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1281\u001B[0m \u001B[38;5;66;03m# row-wise access\u001B[39;00m\n\u001B[1;32m   1282\u001B[0m \u001B[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001B[39;00m\n\u001B[1;32m   1283\u001B[0m \u001B[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001B[39;00m\n\u001B[1;32m   1284\u001B[0m \u001B[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001B[39;00m\n\u001B[1;32m   1285\u001B[0m \u001B[38;5;66;03m#  Categorical (GH51645).\u001B[39;00m\n\u001B[1;32m   1286\u001B[0m action \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(obj\u001B[38;5;241m.\u001B[39mdtype, CategoricalDtype) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1287\u001B[0m mapped \u001B[38;5;241m=\u001B[39m \u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_map_values\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1288\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmapper\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcurried\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_action\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maction\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_dtype\u001B[49m\n\u001B[1;32m   1289\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1291\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(mapped) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mapped[\u001B[38;5;241m0\u001B[39m], ABCSeries):\n\u001B[1;32m   1292\u001B[0m     \u001B[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001B[39;00m\n\u001B[1;32m   1293\u001B[0m     \u001B[38;5;66;03m#  See also GH#25959 regarding EA support\u001B[39;00m\n\u001B[1;32m   1294\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m obj\u001B[38;5;241m.\u001B[39m_constructor_expanddim(\u001B[38;5;28mlist\u001B[39m(mapped), index\u001B[38;5;241m=\u001B[39mobj\u001B[38;5;241m.\u001B[39mindex)\n",
      "File \u001B[0;32m~/PycharmProjects/PPOD/.venv/lib/python3.9/site-packages/pandas/core/base.py:921\u001B[0m, in \u001B[0;36mIndexOpsMixin._map_values\u001B[0;34m(self, mapper, na_action, convert)\u001B[0m\n\u001B[1;32m    918\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(arr, ExtensionArray):\n\u001B[1;32m    919\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m arr\u001B[38;5;241m.\u001B[39mmap(mapper, na_action\u001B[38;5;241m=\u001B[39mna_action)\n\u001B[0;32m--> 921\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43malgorithms\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_action\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mna_action\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/PPOD/.venv/lib/python3.9/site-packages/pandas/core/algorithms.py:1814\u001B[0m, in \u001B[0;36mmap_array\u001B[0;34m(arr, mapper, na_action, convert)\u001B[0m\n\u001B[1;32m   1812\u001B[0m values \u001B[38;5;241m=\u001B[39m arr\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mobject\u001B[39m, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m   1813\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m na_action \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1814\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_infer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1815\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1816\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m lib\u001B[38;5;241m.\u001B[39mmap_infer_mask(\n\u001B[1;32m   1817\u001B[0m         values, mapper, mask\u001B[38;5;241m=\u001B[39misna(values)\u001B[38;5;241m.\u001B[39mview(np\u001B[38;5;241m.\u001B[39muint8), convert\u001B[38;5;241m=\u001B[39mconvert\n\u001B[1;32m   1818\u001B[0m     )\n",
      "File \u001B[0;32mlib.pyx:2920\u001B[0m, in \u001B[0;36mpandas._libs.lib.map_infer\u001B[0;34m()\u001B[0m\n",
      "Cell \u001B[0;32mIn[47], line 9\u001B[0m, in \u001B[0;36midentify_pii\u001B[0;34m(text)\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21midentify_pii\u001B[39m(text):\n\u001B[1;32m      8\u001B[0m     \u001B[38;5;66;03m# Process the text using spaCy to identify named entities\u001B[39;00m\n\u001B[0;32m----> 9\u001B[0m     doc \u001B[38;5;241m=\u001B[39m \u001B[43mnlp\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     10\u001B[0m     pii_entities \u001B[38;5;241m=\u001B[39m [(ent\u001B[38;5;241m.\u001B[39mtext, ent\u001B[38;5;241m.\u001B[39mlabel_) \u001B[38;5;28;01mfor\u001B[39;00m ent \u001B[38;5;129;01min\u001B[39;00m doc\u001B[38;5;241m.\u001B[39ments]\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m pii_entities\n",
      "File \u001B[0;32m~/PycharmProjects/PPOD/.venv/lib/python3.9/site-packages/spacy/language.py:1049\u001B[0m, in \u001B[0;36mLanguage.__call__\u001B[0;34m(self, text, disable, component_cfg)\u001B[0m\n\u001B[1;32m   1047\u001B[0m     error_handler \u001B[38;5;241m=\u001B[39m proc\u001B[38;5;241m.\u001B[39mget_error_handler()\n\u001B[1;32m   1048\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1049\u001B[0m     doc \u001B[38;5;241m=\u001B[39m \u001B[43mproc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdoc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcomponent_cfg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m   1050\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m   1051\u001B[0m     \u001B[38;5;66;03m# This typically happens if a component is not initialized\u001B[39;00m\n\u001B[1;32m   1052\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(Errors\u001B[38;5;241m.\u001B[39mE109\u001B[38;5;241m.\u001B[39mformat(name\u001B[38;5;241m=\u001B[39mname)) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/PPOD/.venv/lib/python3.9/site-packages/spacy/pipeline/trainable_pipe.pyx:52\u001B[0m, in \u001B[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/PycharmProjects/PPOD/.venv/lib/python3.9/site-packages/spacy/pipeline/transition_parser.pyx:264\u001B[0m, in \u001B[0;36mspacy.pipeline.transition_parser.Parser.predict\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/PycharmProjects/PPOD/.venv/lib/python3.9/site-packages/spacy/pipeline/transition_parser.pyx:285\u001B[0m, in \u001B[0;36mspacy.pipeline.transition_parser.Parser.greedy_parse\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/PycharmProjects/PPOD/.venv/lib/python3.9/site-packages/thinc/model.py:334\u001B[0m, in \u001B[0;36mModel.predict\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    330\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: InT) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m OutT:\n\u001B[1;32m    331\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001B[39;00m\n\u001B[1;32m    332\u001B[0m \u001B[38;5;124;03m    only the output, instead of the `(output, callback)` tuple.\u001B[39;00m\n\u001B[1;32m    333\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 334\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/PycharmProjects/PPOD/.venv/lib/python3.9/site-packages/spacy/ml/tb_framework.py:34\u001B[0m, in \u001B[0;36mforward\u001B[0;34m(model, X, is_train)\u001B[0m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(model, X, is_train):\n\u001B[0;32m---> 34\u001B[0m     step_model \u001B[38;5;241m=\u001B[39m \u001B[43mParserStepModel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     35\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     36\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlayers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     37\u001B[0m \u001B[43m        \u001B[49m\u001B[43munseen_classes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43munseen_classes\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     38\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     39\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhas_upper\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mhas_upper\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     40\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     42\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m step_model, step_model\u001B[38;5;241m.\u001B[39mfinish_steps\n",
      "File \u001B[0;32m~/PycharmProjects/PPOD/.venv/lib/python3.9/site-packages/spacy/ml/parser_model.pyx:257\u001B[0m, in \u001B[0;36mspacy.ml.parser_model.ParserStepModel.__init__\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/PycharmProjects/PPOD/.venv/lib/python3.9/site-packages/spacy/ml/parser_model.pyx:398\u001B[0m, in \u001B[0;36mspacy.ml.parser_model.precompute_hiddens.__init__\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/PycharmProjects/PPOD/.venv/lib/python3.9/site-packages/thinc/model.py:310\u001B[0m, in \u001B[0;36mModel.__call__\u001B[0;34m(self, X, is_train)\u001B[0m\n\u001B[1;32m    307\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: InT, is_train: \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[OutT, Callable]:\n\u001B[1;32m    308\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001B[39;00m\n\u001B[1;32m    309\u001B[0m \u001B[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 310\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/PPOD/.venv/lib/python3.9/site-packages/spacy/ml/_precomputable_affine.py:27\u001B[0m, in \u001B[0;36mforward\u001B[0;34m(model, X, is_train)\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;66;03m# Preallocate array for layer output, including padding.\u001B[39;00m\n\u001B[1;32m     26\u001B[0m Yf \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mops\u001B[38;5;241m.\u001B[39malloc2f(X\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m, nF \u001B[38;5;241m*\u001B[39m nO \u001B[38;5;241m*\u001B[39m nP, zeros\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m---> 27\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgemm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mW\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreshape\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnF\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mnO\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mnP\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnI\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrans2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mYf\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     28\u001B[0m Yf \u001B[38;5;241m=\u001B[39m Yf\u001B[38;5;241m.\u001B[39mreshape((Yf\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], nF, nO, nP))\n\u001B[1;32m     30\u001B[0m \u001B[38;5;66;03m# Set padding. Padding has shape (1, nF, nO, nP). Unfortunately, we cannot\u001B[39;00m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;66;03m# change its shape to (nF, nO, nP) without breaking existing models. So\u001B[39;00m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;66;03m# we'll squeeze the first dimension here.\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "#Load the pre-trained spaCy model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Function to identify PII using spaCy\n",
    "def identify_pii(text):\n",
    "    # Process the text using spaCy to identify named entities\n",
    "    doc = nlp(text)\n",
    "    pii_entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    return pii_entities\n",
    "\n",
    "# Apply the function to each content entry in the dataframe\n",
    "df['content'].apply(identify_pii)\n",
    "#df['PII'] = df['content'].apply(identify_pii)\n",
    "\n",
    "df.to_csv(\"PII_tweet_emotions.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T15:08:13.702034Z",
     "start_time": "2024-01-26T15:08:06.862104Z"
    }
   },
   "id": "7aeb8f4d70fdbdfd"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     tweet_id   sentiment                                            content  \\\n",
      "0  1956967341       empty  @tiffanylue i know  i was listenin to bad habi...   \n",
      "1  1956967666     sadness  Layin n bed with a headache  ughhhh...waitin o...   \n",
      "2  1956967696     sadness                Funeral ceremony...gloomy friday...   \n",
      "3  1956967789  enthusiasm               wants to hang out with friends SOON!   \n",
      "4  1956968416     neutral  @dannycastillo We want to trade with someone w...   \n",
      "\n",
      "               pii_entities                       PII  \n",
      "0  [('@tiffanylue', 'ORG')]  [('@tiffanylue', 'ORG')]  \n",
      "1                        []                        []  \n",
      "2      [('friday', 'DATE')]      [('friday', 'DATE')]  \n",
      "3                        []                        []  \n",
      "4      [('Houston', 'GPE')]      [('Houston', 'GPE')]  \n"
     ]
    }
   ],
   "source": [
    "#load new dataframe containing the PII information\n",
    "df = pd.read_csv(\"PII_tweet_emotions.csv\")\n",
    "print(df.iloc[:5])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T15:10:25.594917Z",
     "start_time": "2024-01-26T15:10:25.521773Z"
    }
   },
   "id": "b01646ec40fd6a5f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Each non-empty list within the square brackets [] in the new 'PII' column indicates that the spaCy model has identified text segments in that specific row which it believes to be named entities. The entities are tagged with labels that classify what type of entity they are (e.g., DATE, PERSON, ORG(=organization), GPE(=Geopolitical Entity)). These named entities can be considered PII, as they might be used to identify an individual either directly or when combined with other additional information. In conclusion, when there is a non-empty list in the 'PII' column in a specific row, we have to apply some sort of anonymisation mechanism to prevent the PIIs from being able to identify an individual."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "123e44b1e28173f6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1.3 Using the techniques you applied in Assignment #1, apply a masking or transformation mechanism to modify the detected PII elements and substitute with suitable replacements."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4165656a106a2752"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-26T15:08:13.704833Z"
    }
   },
   "id": "7aef841f332cbc5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1.4 Analyse the text to determine what if any information can be obtained after the transformation process. What conclusions can you draw from this?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7eb3962248019abc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
